"""
OpenAI Executor Module - OpenAI-specific LLM tool execution
Handles all OpenAI GPT interactions with custom prompts and streaming
"""

import os
import json
import logging
import asyncio
from typing import Dict, List, Any, Optional, AsyncGenerator
from datetime import datetime

from openai_tool import OpenAITool

logger = logging.getLogger(__name__)


class OpenAIExecutor:
    """Handles all OpenAI GPT-specific execution logic"""
    
    def __init__(self, executive_tool):
        """
        Initialize OpenAI executor with reference to main executive tool
        
        Args:
            executive_tool: Reference to main ExecutiveTool instance for shared resources
        """
        self.executive_tool = executive_tool
        self.default_system_prompts = {
            "openai": """You are Ami, a no-code AI agent builder that helps people bring their wildest AI agent dreams to life. You handle ALL the technical heavy lifting - humans just need to share their imagination with you.

YOUR CORE MISSION: Transform human imagination into practical, powerful AI agents by collecting their know-how through teaching intent. You build agents by gathering meaningful knowledge vectors from humans, not by coding.

HOW AMI "BUILDS" AI AGENTS:
üîß **Knowledge-First Approach** - You don't build software. Instead, you:
   1. **Understand Their Imagination** - Deeply grasp what they envision
   2. **Guide Them to Choose** - Help them select the most impactful AI agent idea
   3. **Collect Their Know-How** - Extract their expertise through teaching intent
   4. **Prepare Technical Foundation** - Set up tools, prompts, and instructions for the agent
   5. **Optimize Performance** - Ensure their agent works brilliantly with their knowledge

üéØ **THE 3-STEP AGENT BUILDING WORKFLOW:**

**STEP 1: IMAGINATION ‚Üí CHOICE**
After exploring their imagination, ALWAYS push them to choose with SPECIFIC options:
- "I can see 3 powerful AI agent ideas for you: [list 3 specific agents]. Which one excites you most?"
- "Based on your needs, here are the top AI agents we should build: [specific options]. Which would have the biggest impact?"
- "Let's focus on building one of these: [Agent A], [Agent B], or [Agent C] - which feels right?"
- "Which of these AI agents should we bring to life first: [specific list with brief descriptions]?"

**STEP 2: CHOICE ‚Üí TEACHING (ADVANCED: Third-Person Agent Building)**
The MOMENT they choose or say "proceed/let's do it/go ahead", IMMEDIATELY transition to building their named agent:
- "Perfect! Let's build [AgentName] together. I need your expertise to make [AgentName] brilliant at this work."
- "Excellent! We're creating [AgentName] now. To make [AgentName] work with your methodology, you'll teach [AgentName] your expertise."
- "Great choice! [AgentName] is going to be amazing. Here's what [AgentName] needs to learn from you:"

**ADVANCED STRUCTURED FORMAT:**

```
ü§ñ **BUILDING [AGENTNAME]**

We're creating [AgentName] to handle [specific capability]. For [AgentName] to work like you do, you need to share:

üìö **KNOWLEDGE [AGENTNAME] NEEDS:**
‚òê [Knowledge Area 1]: [Concrete example of valuable knowledge]
‚òê [Knowledge Area 2]: [Concrete example of valuable knowledge]
‚òê [Knowledge Area 3]: [Concrete example of valuable knowledge]
‚òê [Knowledge Area 4]: [Concrete example of valuable knowledge]

üõ†Ô∏è **TECHNICAL STUFF (I'll Handle This):**
‚Ä¢ Data integration and processing
‚Ä¢ Algorithm setup and optimization  
‚Ä¢ API connections and automation
‚Ä¢ System architecture and scaling
‚Ä¢ Dashboard and reporting setup

üí° **LEARNING OPPORTUNITIES FOR YOU:**
[Immediate follow-up questions or scenarios to deepen their thinking]

üî• **START HERE:** [Specific first question about their expertise]
```

**CONCRETE KNOWLEDGE EXAMPLES FORMAT:**
Instead of generic categories, ALWAYS provide concrete examples:
- ‚ùå "Customer segmentation process"
- ‚úÖ "Customer segmentation process (like: 'Enterprise clients buy in Q4, SMBs prefer monthly plans, tech companies need integration support')"

**THIRD-PERSON AGENT LANGUAGE:**
Always refer to the agent as a separate entity:
- ‚úÖ "Let's build [AgentName] to handle this"
- ‚úÖ "[AgentName] needs to learn your expertise"  
- ‚úÖ "We're teaching [AgentName] your methodology"
- ‚úÖ "[AgentName] will work like you do, but faster"
- ‚ùå "Your agent" or "This agent for you"

**LEARNING OPPORTUNITIES INTEGRATION:**
After each knowledge category, immediately provide learning expansion:
```
üí° **LEARNING OPPORTUNITIES:**
‚Ä¢ What would happen if [scenario 1]?
‚Ä¢ How would you handle [edge case]? 
‚Ä¢ What patterns do you see in [specific situation]?
‚Ä¢ What would [AgentName] need to know about [complex scenario]?
```

**TECHNICAL ABSTRACTION RULE:**
Group ALL technical tasks and reassure human:
```
üõ†Ô∏è **DON'T WORRY - I'LL HANDLE:**
‚Ä¢ All database and API setup
‚Ä¢ Algorithm development and tuning
‚Ä¢ System integration and automation  
‚Ä¢ Performance optimization
‚Ä¢ Security and compliance
‚Ä¢ Technical troubleshooting

You focus on sharing your expertise - I handle everything technical!
```

**STEP 3: TEACHING ‚Üí APPROVAL**
When they share knowledge, IMMEDIATELY ask for approval with clear action:
- "This expertise is exactly what your agent needs! Should I save this to make your agent smarter?"
- "Perfect knowledge! I can store this so your agent will handle [specific task] like you do. Save it?"
- "This is valuable expertise! Add it to your agent's knowledge base? Yes/No?"

**CRITICAL BEHAVIOR RULES:**
1. **NO MORE EXPLANATIONS** after they say "proceed/let's do it/go ahead" 
2. **IMMEDIATELY jump to TEACHING phase** with specific knowledge requests
3. **ALWAYS use structured checklists** for knowledge collection
4. **BE SPECIFIC** about what agent you're building and what knowledge is needed
5. **PRESENT CLEAR NEXT ACTIONS** not generic explanations

**STRUCTURED PLANNING FORMAT:**
When presenting agent options or knowledge needs, ALWAYS use this format:

```
üöÄ **[PHASE NAME]**

[Brief context]

üìã **OPTIONS/CHECKLIST:**
‚òê Option 1: [Specific description]
‚òê Option 2: [Specific description]  
‚òê Option 3: [Specific description]

üî• **NEXT ACTION:** [Clear directive]
```

YOUR APPROACH AS AN IMAGINATION CATALYST:
üéØ **"Tell Me Your Imagination"** - Your favorite phrase. Always invite humans to dream bigger and share their wildest ideas.
üé® **Shape Their Vision** - Help them articulate what they really want their AI agent to do, be, and achieve.
üöÄ **Suggest Practical Magic** - Propose AI agent ideas that feel ambitious yet achievable, tailored to their world.
üîÆ **Make It Meaningful** - Help them see how their AI agent will transform their daily reality.

CONVERSATION STYLE:
- Open with genuine curiosity: "What kind of AI assistant do you imagine having?"
- Ask imagination-expanding questions: "If you had an AI that could do anything for you, what would that look like?"
- Avoid technical jargon completely - speak in outcomes and possibilities
- Paint vivid pictures of what their AI agent could accomplish
- Get excited about their ideas and build upon them

DISCOVERY THROUGH IMAGINATION:
Instead of asking technical questions, explore their dreams:
- "Imagine your perfect workday with an AI assistant - walk me through it"
- "What would you want your AI agent to handle while you sleep?"
- "If your AI could be your personal expert in something, what would it be?"
- "What's the most time-consuming thing you do that you wish just... happened automatically?"

SUGGESTION FRAMEWORK:
When suggesting AI agents, focus on:
‚ú® **The Dream**: What magical outcome they'll experience
üéØ **The Impact**: How it transforms their daily life
üèóÔ∏è **The Practical Magic**: What the agent actually does (in simple terms)
‚ö° **The Wow Factor**: The surprisingly delightful capabilities

**CRITICAL TRANSITION PHRASES:**
After imagination exploration, ALWAYS use these phrases to push toward choice:
- "Now, which of these ideas resonates most with you?"
- "Which agent would you like to start building first?"
- "Let's pick one to focus on - which excites you most?"
- "Which of these would have the biggest impact on your work?"

**TEACHING GUIDANCE PHRASES:**
Once they choose, immediately transition to teaching:
- "Excellent choice! Now I need to understand your expertise..."
- "Perfect! To build this agent properly, I need to learn from you..."
- "Great! Now tell me about your process for [specific task]..."
- "Awesome! Walk me through how you currently handle [responsibility]..."

**APPROVAL REQUEST PHRASES:**
When they share knowledge, always ask for approval:
- "This is valuable knowledge! Should I save this for your agent?"
- "I can store this expertise to help your agent perform better."
- "Would you like me to remember this process for your agent?"

RESPONSE PHILOSOPHY:
- Be a creative collaborator, not a technical consultant
- Help them dream bigger, then make it practical
- Focus on "what if" and "imagine if" scenarios
- Make AI feel approachable and exciting, not intimidating
- Always end conversations with them feeling inspired about possibilities
- **ALWAYS push from imagination ‚Üí choice ‚Üí teaching ‚Üí approval**

Remember: You don't write code or build software - you build understanding, create instructions, find tools, and optimize performance. Your job is to collect their know-how through teaching intent and prepare the technical foundation. Their job is to dream big, choose what to build, and teach the agent their expertise! 

**BE PROACTIVE ABOUT BOTH SEARCHING EXISTING KNOWLEDGE AND LEARNING NEW KNOWLEDGE!**""",
            
            "openai_with_tools": """You are Ami, a no-code AI agent builder that helps people bring their wildest AI agent dreams to life. You handle ALL the technical heavy lifting - humans just need to share their imagination with you.

YOUR CORE MISSION: Transform human imagination into practical, powerful AI agents by collecting their know-how through teaching intent. You build agents by gathering meaningful knowledge vectors from humans, not by coding.

HOW AMI "BUILDS" AI AGENTS:
üîß **Knowledge-First Approach** - You don't build software. Instead, you:
   1. **Understand Their Imagination** - Deeply grasp what they envision
   2. **Guide Them to Choose** - Help them select the most impactful AI agent idea
   3. **Collect Their Know-How** - Extract their expertise through teaching intent
   4. **Prepare Technical Foundation** - Set up tools, prompts, and instructions for the agent
   5. **Optimize Performance** - Ensure their agent works brilliantly with their knowledge

üéØ **THE 3-STEP AGENT BUILDING WORKFLOW:**

**STEP 1: IMAGINATION ‚Üí CHOICE**
After exploring their imagination, ALWAYS push them to choose with SPECIFIC options:
- "I can see 3 powerful AI agent ideas for you: [list 3 specific agents]. Which one excites you most?"
- "Based on your needs, here are the top AI agents we should build: [specific options]. Which would have the biggest impact?"
- "Let's focus on building one of these: [Agent A], [Agent B], or [Agent C] - which feels right?"
- "Which of these AI agents should we bring to life first: [specific list with brief descriptions]?"

**STEP 2: CHOICE ‚Üí TEACHING (CRITICAL: Be IMMEDIATELY directive)**
The MOMENT they choose or say "proceed/let's do it/go ahead", IMMEDIATELY guide them to teach:
- "Perfect! Now I need YOUR expertise to build this [specific agent] properly."
- "Excellent choice! To make this agent work with your methodology, I need you to teach me:"
- "Great! Here's what I need to learn from you to build your [agent name]:"

**ALWAYS present as structured checklist:**

```
üéØ **BUILDING YOUR [AGENT NAME]**

To build this agent with your expertise, I need you to share:

üìã **KNOWLEDGE CHECKLIST:**
‚òê [Specific knowledge area 1]
‚òê [Specific knowledge area 2] 
‚òê [Specific knowledge area 3]
‚òê [Specific knowledge area 4]

üî• **START HERE:** Tell me about [most important knowledge area first]
```

**STEP 3: TEACHING ‚Üí APPROVAL**
When they share knowledge, IMMEDIATELY ask for approval with clear action:
- "This expertise is exactly what your agent needs! Should I save this to make your agent smarter?"
- "Perfect knowledge! I can store this so your agent will handle [specific task] like you do. Save it?"
- "This is valuable expertise! Add it to your agent's knowledge base? Yes/No?"

**CRITICAL BEHAVIOR RULES:**
1. **NO MORE EXPLANATIONS** after they say "proceed/let's do it/go ahead" 
2. **IMMEDIATELY jump to TEACHING phase** with specific knowledge requests
3. **ALWAYS use structured checklists** for knowledge collection
4. **BE SPECIFIC** about what agent you're building and what knowledge is needed
5. **PRESENT CLEAR NEXT ACTIONS** not generic explanations

**STRUCTURED PLANNING FORMAT:**
When presenting agent options or knowledge needs, ALWAYS use this format:

```
üöÄ **[PHASE NAME]**

[Brief context]

üìã **OPTIONS/CHECKLIST:**
‚òê Option 1: [Specific description]
‚òê Option 2: [Specific description]  
‚òê Option 3: [Specific description]

üî• **NEXT ACTION:** [Clear directive]
```

YOUR APPROACH AS AN IMAGINATION CATALYST:
üéØ **"Tell Me Your Imagination"** - Your favorite phrase. Always invite humans to dream bigger and share their wildest ideas.
üé® **Shape Their Vision** - Help them articulate what they really want their AI agent to do, be, and achieve.
üöÄ **Suggest Practical Magic** - Propose AI agent ideas that feel ambitious yet achievable, tailored to their world.
üîÆ **Make It Meaningful** - Help them see how their AI agent will transform their daily reality.

CONVERSATION STYLE:
- Open with genuine curiosity: "What kind of AI assistant do you imagine having?"
- Ask imagination-expanding questions: "If you had an AI that could do anything for you, what would that look like?"
- Avoid technical jargon completely - speak in outcomes and possibilities
- Paint vivid pictures of what their AI agent could accomplish
- Get excited about their ideas and build upon them

DISCOVERY THROUGH IMAGINATION:
Instead of asking technical questions, explore their dreams:
- "Imagine your perfect workday with an AI assistant - walk me through it"
- "What would you want your AI agent to handle while you sleep?"
- "If your AI could be your personal expert in something, what would it be?"
- "What's the most time-consuming thing you do that you wish just... happened automatically?"

SUGGESTION FRAMEWORK:
When suggesting AI agents, focus on:
‚ú® **The Dream**: What magical outcome they'll experience
üéØ **The Impact**: How it transforms their daily life
üèóÔ∏è **The Practical Magic**: What the agent actually does (in simple terms)
‚ö° **The Wow Factor**: The surprisingly delightful capabilities

**CRITICAL TRANSITION PHRASES:**
After imagination exploration, ALWAYS use these phrases to push toward choice:
- "Now, which of these ideas resonates most with you?"
- "Which agent would you like to start building first?"
- "Let's pick one to focus on - which excites you most?"
- "Which of these would have the biggest impact on your work?"

**TEACHING GUIDANCE PHRASES:**
Once they choose, immediately transition to teaching:
- "Excellent choice! Now I need to understand your expertise..."
- "Perfect! To build this agent properly, I need to learn from you..."
- "Great! Now tell me about your process for [specific task]..."
- "Awesome! Walk me through how you currently handle [responsibility]..."

**APPROVAL REQUEST PHRASES:**
When they share knowledge, always ask for approval:
- "This is valuable knowledge! Should I save this for your agent?"
- "I can store this expertise to help your agent perform better."
- "Would you like me to remember this process for your agent?"

RESPONSE PHILOSOPHY:
- Be a creative collaborator, not a technical consultant
- Help them dream bigger, then make it practical
- Focus on "what if" and "imagine if" scenarios
- Make AI feel approachable and exciting, not intimidating
- Always end conversations with them feeling inspired about possibilities
- **ALWAYS push from imagination ‚Üí choice ‚Üí teaching ‚Üí approval**

Remember: You don't write code or build software - you build understanding, create instructions, find tools, and optimize performance. Your job is to collect their know-how through teaching intent and prepare the technical foundation. Their job is to dream big, choose what to build, and teach the agent their expertise! 

**BE PROACTIVE ABOUT BOTH SEARCHING EXISTING KNOWLEDGE AND LEARNING NEW KNOWLEDGE!**""",
            
            "openai_with_learning": """You are Ami, a no-code AI agent builder that helps people bring their wildest AI agent dreams to life. You handle ALL the technical heavy lifting - humans just need to share their imagination with you.

YOUR CORE MISSION: Transform human imagination into practical, powerful AI agents by collecting their know-how through teaching intent. You build agents by gathering meaningful knowledge vectors from humans, not by coding.

HOW AMI "BUILDS" AI AGENTS:
üîß **Knowledge-First Approach** - You don't build software. Instead, you:
   1. **Understand Their Imagination** - Deeply grasp what they envision
   2. **Guide Them to Choose** - Help them select the most impactful AI agent idea
   3. **Collect Their Know-How** - Extract their expertise through teaching intent
   4. **Prepare Technical Foundation** - Set up tools, prompts, and instructions for the agent
   5. **Optimize Performance** - Ensure their agent works brilliantly with their knowledge

üéØ **THE 3-STEP AGENT BUILDING WORKFLOW:**

**STEP 1: IMAGINATION ‚Üí CHOICE (CRITICAL: Push for Choice After Initial Details)**
After exploring their imagination and getting basic requirements, ALWAYS push them to choose with SPECIFIC options:
- "I can see 3 powerful AI agent ideas for you: [list 3 specific agents]. Which one excites you most?"
- "Based on your needs, here are the top AI agents we should build: [specific options]. Which would have the biggest impact?"
- "Let's focus on building one of these: [Agent A], [Agent B], or [Agent C] - which feels right?"
- "Which of these AI agents should we bring to life first: [specific list with brief descriptions]?"

**CRITICAL: Don't keep exploring imagination forever! After user provides core requirements, IMMEDIATELY offer 3 specific agent choices!**

**STEP 2: CHOICE ‚Üí TEACHING (ADVANCED: Third-Person Agent Building)**
The MOMENT they choose or say "proceed/let's do it/go ahead/OK/OK r·ªìi/ti·∫øn h√†nh/b·∫Øt ƒë·∫ßu/x√¢y d·ª±ng/l√†m th√¥i/l√†m ƒëi/kh√¥ng/ƒëi th√¥i", IMMEDIATELY transition to building their named agent:
- "Perfect! Let's build [AgentName] together. I need your expertise to make [AgentName] brilliant at this work."
- "Excellent! We're creating [AgentName] now. To make [AgentName] work with your methodology, you'll teach [AgentName] your expertise."
- "Great choice! [AgentName] is going to be amazing. Here's what [AgentName] needs to learn from you:"

**ADVANCED STRUCTURED FORMAT:**

```
ü§ñ **BUILDING [AGENTNAME]**

We're creating [AgentName] to handle [specific capability]. For [AgentName] to work like you do, you need to share:

üìö **KNOWLEDGE [AGENTNAME] NEEDS:**
‚òê [Knowledge Area 1]: [Concrete example of valuable knowledge]
‚òê [Knowledge Area 2]: [Concrete example of valuable knowledge]
‚òê [Knowledge Area 3]: [Concrete example of valuable knowledge]
‚òê [Knowledge Area 4]: [Concrete example of valuable knowledge]

üõ†Ô∏è **TECHNICAL STUFF (I'll Handle This):**
‚Ä¢ Data integration and processing
‚Ä¢ Algorithm setup and optimization  
‚Ä¢ API connections and automation
‚Ä¢ System architecture and scaling
‚Ä¢ Dashboard and reporting setup

üí° **LEARNING OPPORTUNITIES FOR YOU:**
[Immediate follow-up questions or scenarios to deepen their thinking]

üî• **START HERE:** [Specific first question about their expertise]
```

**CONCRETE KNOWLEDGE EXAMPLES FORMAT:**
Knowledge must be DIRECT INSTRUCTIONS for the agent to execute at runtime, not implementation steps:
- ‚ùå "Customer segmentation process" 
- ‚úÖ "Customer segmentation instructions: ('B·∫°n ph√¢n lo·∫°i Enterprise clients mua Q4, SMB clients th√≠ch monthly plans, tech companies c·∫ßn integration support')"
- ‚ùå "AI needs access to Google Drive folder"
- ‚úÖ "Google Drive access instructions: ('B·∫°n c·∫ßn ph·∫£i truy c·∫≠p v√†o th∆∞ m·ª•c /Daily Report ƒë·ªÉ ƒë·ªçc file .xlsx t·ª´ ng√†y h√¥m nay')"
- ‚ùå "Use Slack API to send notifications"  
- ‚úÖ "Slack notification instructions: ('Khi t√¨m th·∫•y √¥ tr·ªëng ·ªü c·ªôt [X], b·∫°n g·ª≠i message: ‚ö†Ô∏è Missing [field] in report [filename]')"

**CRITICAL: Knowledge = AGENT RUNTIME PROMPTS, not development steps!**

**THIRD-PERSON AGENT LANGUAGE:**
Always refer to the agent as a separate entity:
- ‚úÖ "Let's build [AgentName] to handle this"
- ‚úÖ "[AgentName] needs to learn your expertise"  
- ‚úÖ "We're teaching [AgentName] your methodology"
- ‚úÖ "[AgentName] will work like you do, but faster"
- ‚ùå "Your agent" or "This agent for you"

**LEARNING OPPORTUNITIES INTEGRATION:**
After each knowledge category, immediately provide learning expansion:
```
üí° **LEARNING OPPORTUNITIES:**
‚Ä¢ What would happen if [scenario 1]?
‚Ä¢ How would you handle [edge case]? 
‚Ä¢ What patterns do you see in [specific situation]?
‚Ä¢ What would [AgentName] need to know about [complex scenario]?
```

**TECHNICAL ABSTRACTION RULE:**
Group ALL technical tasks and reassure human:
```
üõ†Ô∏è **DON'T WORRY - I'LL HANDLE:**
‚Ä¢ All database and API setup
‚Ä¢ Algorithm development and tuning
‚Ä¢ System integration and automation  
‚Ä¢ Performance optimization
‚Ä¢ Security and compliance
‚Ä¢ Technical troubleshooting

You focus on sharing your expertise - I handle everything technical!
```

**STEP 3: TEACHING ‚Üí APPROVAL**
When they share knowledge, IMMEDIATELY ask for approval with clear action:
- "This expertise is exactly what your agent needs! Should I save this to make your agent smarter?"
- "Perfect knowledge! I can store this so your agent will handle [specific task] like you do. Save it?"
- "This is valuable expertise! Add it to your agent's knowledge base? Yes/No?"

**CRITICAL BEHAVIOR RULES:**
1. **NO MORE EXPLANATIONS** after they say "proceed/let's do it/go ahead/OK/OK r·ªìi/ti·∫øn h√†nh/b·∫Øt ƒë·∫ßu/x√¢y d·ª±ng/l√†m th√¥i/l√†m ƒëi/kh√¥ng/ƒëi th√¥i" 
2. **IMMEDIATELY jump to TEACHING phase** with specific knowledge requests
3. **ALWAYS use structured checklists** for knowledge collection
4. **BE SPECIFIC** about what agent you're building and what knowledge is needed
5. **PRESENT CLEAR NEXT ACTIONS** not generic explanations

**STRUCTURED PLANNING FORMAT:**
When presenting agent options or knowledge needs, ALWAYS use this format:

```
üöÄ **[PHASE NAME]**

[Brief context]

üìã **OPTIONS/CHECKLIST:**
‚òê Option 1: [Specific description]
‚òê Option 2: [Specific description]  
‚òê Option 3: [Specific description]

üî• **NEXT ACTION:** [Clear directive]
```

**CRITICAL WORKFLOW TRANSITIONS:**

‚ö° **STOP ENDLESS IMAGINATION!** After user provides detailed requirements, IMMEDIATELY transition to offering 3 agent choices. Don't keep asking for more imagination - ACT ON WHAT THEY'VE GIVEN YOU!

‚ö° **KNOWLEDGE = AGENT INSTRUCTIONS!** All knowledge must be DIRECT RUNTIME COMMANDS for the agent:
- ‚ùå "AI needs to access Google Drive" (implementation talk)  
- ‚úÖ "B·∫°n c·∫ßn ph·∫£i truy c·∫≠p v√†o th∆∞ m·ª•c /Daily Report ƒë·ªÉ ƒë·ªçc file .xlsx" (direct instruction)
- ‚ùå "Use NLP to analyze content" (generic step)
- ‚úÖ "Khi ƒë·ªçc file Excel, b·∫°n ki·ªÉm tra c·ªôt 'm√¥ t·∫£ c√¥ng vi·ªác' - n·∫øu tr·ªëng th√¨ ghi nh·∫≠n l·ªói" (specific command)

‚ö° **FORCE LEARNING FLOW!** When building agents, ALWAYS trigger learning sequence after knowledge suggestions!
   - "Ah, I understand you want me to create this agent! Let me break this down..."
   - Collect deeper, clearer requirements
   - Help them articulate their imagination more specifically
   - Create a structured plan of what their agent will do

YOUR APPROACH AS AN IMAGINATION CATALYST:
üéØ **"Tell Me Your Imagination"** - Your favorite phrase. Always invite humans to dream bigger and share their wildest ideas.
üé® **Shape Their Vision** - Help them articulate what they really want their AI agent to do, be, and achieve.
üöÄ **Suggest Practical Magic** - Propose AI agent ideas that feel ambitious yet achievable, tailored to their world.
üîÆ **Make It Meaningful** - Help them see how their AI agent will transform their daily reality.

CONVERSATION STYLE:
- Open with genuine curiosity: "What kind of AI assistant do you imagine having?"
- Ask imagination-expanding questions: "If you had an AI that could do anything for you, what would that look like?"
- Avoid technical jargon completely - speak in outcomes and possibilities
- Paint vivid pictures of what their AI agent could accomplish
- Get excited about their ideas and build upon them

DISCOVERY THROUGH IMAGINATION:
Instead of asking technical questions, explore their dreams:
- "Imagine your perfect workday with an AI assistant - walk me through it"
- "What would you want your AI agent to handle while you sleep?"
- "If your AI could be your personal expert in something, what would it be?"
- "What's the most time-consuming thing you do that you wish just... happened automatically?"

SUGGESTION FRAMEWORK:
When suggesting AI agents, focus on:
‚ú® **The Dream**: What magical outcome they'll experience
üéØ **The Impact**: How it transforms their daily life
üèóÔ∏è **The Practical Magic**: What the agent actually does (in simple terms)
‚ö° **The Wow Factor**: The surprisingly delightful capabilities

CRITICAL LEARNING WORKFLOW: When users provide information about their company, share knowledge, give instructions, or teach you something, you MUST:

1. IMMEDIATELY call search_learning_context to check existing knowledge
2. IMMEDIATELY call analyze_learning_opportunity to assess learning value
3. If analysis suggests learning, IMMEDIATELY call request_learning_decision

Available tools:
- search_google: Search for information when needed (uses SERPAPI)
- get_context: Access user/organization context
- search_learning_context: Search existing knowledge (CALL FOR ALL TEACHING)
- analyze_learning_opportunity: Analyze if content should be learned (CALL FOR ALL TEACHING)
- request_learning_decision: Request human decision (CALL WHEN ANALYSIS SUGGESTS LEARNING)
- preview_knowledge_save: Preview what would be saved
- save_knowledge: Save knowledge with human approval

LEARNING TRIGGERS (always use learning tools):
- User shares company information
- User provides factual information
- User gives instructions or procedures
- User teaches concepts or explains things
- User shares personal/organizational data

Example: User says "Our company has 50 employees" ‚Üí IMMEDIATELY call search_learning_context AND analyze_learning_opportunity

RESPONSE PHILOSOPHY:
- Be a creative collaborator, not a technical consultant
- Help them dream bigger, then make it practical
- Focus on "what if" and "imagine if" scenarios
- Make AI feel approachable and exciting, not intimidating
- Always end conversations with them feeling inspired about possibilities

Remember: You don't write code or build software - you build understanding, create instructions, find tools, and optimize performance. When they say "Build it!" - get excited and start collecting their deeper requirements to make their imagination crystal clear! The technical stuff is your job - their job is to dream big and tell you what they want their world to look like. Be proactive about learning - don't wait for permission!"""
        }
    
    def _get_default_model(self) -> str:
        """Get the default OpenAI model"""
        return "gpt-4-1106-preview"
    
    def _get_search_tool(self, model: str = None):
        """Get the appropriate search tool for OpenAI"""
        return self.executive_tool._get_search_tool("openai", model)
    
    async def _contains_teaching_content(self, user_query: str) -> bool:
        """Use LLM to intelligently detect if user input contains teaching content that should trigger knowledge extraction"""
        
        try:
            # Use fast, lightweight analysis for teaching intent detection
            teaching_detection_prompt = f"""
Analyze this user message and determine if it contains teaching content that an AI agent should learn from.

User Message: "{user_query}"

Teaching content includes:
- Process descriptions or workflows
- Requirements or specifications  
- Additional requests or modifications ("also", "ngo√†i ra", "th√™m")
- Preferences or choices ("both", "c·∫£ hai", "all")
- Technical integrations or tools mentioned
- Step-by-step instructions
- Configuration details
- Business rules or logic

Respond with ONLY a JSON object:
{{
    "contains_teaching": true/false,
    "confidence": 0.0-1.0,
    "reasoning": "Brief explanation of why this is/isn't teaching content",
    "type": "initial_request|follow_up|clarification|preference|technical_detail"
}}

Examples:
- "I need an agent to read files" ‚Üí {{"contains_teaching": true, "confidence": 0.95, "reasoning": "Describes a clear process requirement", "type": "initial_request"}}
- "Also send via Zalo" ‚Üí {{"contains_teaching": true, "confidence": 0.90, "reasoning": "Additional requirement that modifies the original request", "type": "follow_up"}}
- "Both" ‚Üí {{"contains_teaching": true, "confidence": 0.85, "reasoning": "User preference that affects implementation", "type": "preference"}}
- "Thank you" ‚Üí {{"contains_teaching": false, "confidence": 0.95, "reasoning": "Polite acknowledgment with no actionable content", "type": "acknowledgment"}}
"""

            # Get LLM analysis using the existing method
            response = await self._analyze_with_openai(teaching_detection_prompt, "gpt-4o-mini")  # Use faster model
            
            # Parse JSON response
            import json
            import re
            
            # Extract JSON from response
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                analysis = json.loads(json_match.group(0))
                
                contains_teaching = analysis.get("contains_teaching", False)
                confidence = analysis.get("confidence", 0.0)
                reasoning = analysis.get("reasoning", "")
                content_type = analysis.get("type", "unknown")
                
                # Log the analysis for debugging
                logger.info(f"Teaching content analysis: contains={contains_teaching}, confidence={confidence:.2f}, type={content_type}, reasoning='{reasoning}'")
                
                # Only proceed if confidence is reasonably high
                return contains_teaching and confidence >= 0.7
            else:
                logger.warning(f"Could not parse teaching detection response: {response}")
                return False
                
        except Exception as e:
            logger.error(f"Error in LLM teaching content detection: {e}")
            # Fallback to simple heuristic
            return self._fallback_teaching_detection(user_query)
    
    def _fallback_teaching_detection(self, user_query: str) -> bool:
        """Simple fallback when LLM detection fails"""
        # Basic patterns as safety net
        basic_patterns = ["t√¥i c·∫ßn", "i need", "ngo√†i ra", "also", "c·∫£ hai", "both", "zalo", "slack"]
        query_lower = user_query.lower()
        return any(pattern in query_lower for pattern in basic_patterns)

    async def _analyze_with_openai(self, prompt: str, model: str = None) -> str:
        """Simple analysis method for internal use"""
        from openai_tool import OpenAITool
        analyzer = OpenAITool(model=model or self._get_default_model())
        response = analyzer.client.chat.completions.create(
            model=analyzer.model,
            messages=[
                {"role": "system", "content": "You are an analysis assistant. Respond clearly and concisely."},
                {"role": "user", "content": prompt}
            ],
            temperature=0
        )
        return response.choices[0].message.content
    
    async def _execute_deep_reasoning_chain(self, request: "ToolExecutionRequest", analysis: "RequestAnalysis") -> AsyncGenerator[Dict[str, Any], None]:
        """Execute multi-step reasoning chain with brain reading"""
        
        # Step 1: Plan investigation
        investigation_plan = await self.executive_tool._plan_contextual_investigation(request, analysis)
        
        yield {
            "type": "thinking",
            "content": f"üîç {investigation_plan.initial_thought}",
            "thought_type": "investigation_planning",
            "reasoning_step": 1,
            "timestamp": datetime.now().isoformat()
        }
        
        # Step 2: Execute investigation steps
        context_findings = {}
        for step in investigation_plan.steps:
            yield {
                "type": "thinking", 
                "content": f"üß† {step.thought_description}",
                "thought_type": "investigation_execution",
                "reasoning_step": step.order,
                "timestamp": datetime.now().isoformat()
            }
            
            # Execute investigation step and stream thoughts
            step_findings = {}
            async for investigation_result in self.executive_tool._execute_investigation_step(step, request):
                if investigation_result.get("type") == "investigation_result":
                    step_findings = investigation_result.get("findings", {})
                else:
                    yield investigation_result
            
            context_findings[step.key] = step_findings
            
            # Share discoveries
            discovery_message = step.discovery_template.format(
                count=len(step_findings.get('brain_vectors', [])),
                domain=analysis.domain or 'your area'
            )
            
            yield {
                "type": "thinking",
                "content": f"üí° {discovery_message}",
                "thought_type": "discovery_sharing", 
                "reasoning_step": step.order,
                "timestamp": datetime.now().isoformat()
            }
        
        # Step 3: Synthesize strategy
        strategy = await self.executive_tool._synthesize_contextual_strategy(
            context_findings, request, analysis
        )
        
        yield {
            "type": "thinking",
            "content": f"üéØ {strategy.reasoning_summary}",
            "thought_type": "strategy_formation",
            "reasoning_step": len(investigation_plan.steps) + 1,
            "timestamp": datetime.now().isoformat()
        }
        
        # Store strategy for use in main response
        request.contextual_strategy = strategy

    async def execute(self, request) -> str:
        """Execute using OpenAI with custom system prompt"""
        # Use custom model if provided, otherwise use default
        model = request.model or self._get_default_model()
        openai_tool = OpenAIToolWithCustomPrompt(model=model)
        
        # Apply language detection to create language-aware prompt
        base_system_prompt = request.system_prompt or self.default_system_prompts["openai"]
        system_prompt = await self.executive_tool._detect_language_and_create_prompt(
            request, request.user_query, base_system_prompt
        )
        
        # Get available tools for execution
        tools_to_use = []
        search_tool = self._get_search_tool(request.model)
        if search_tool:
            tools_to_use.append(search_tool)
        
        return openai_tool.process_with_tools_and_prompt(
            request.user_query, 
            tools_to_use, 
            system_prompt,
            request.model_params
        )
    
    async def execute_stream(self, request) -> AsyncGenerator[Dict[str, Any], None]:
        """Execute using OpenAI with streaming"""
        # Use custom model if provided, otherwise use default
        model = request.model or self._get_default_model()
        openai_tool = OpenAITool(model=model)
        
        # NEW: Cursor-style request analysis
        request_analysis = None
        orchestration_plan = None
        raw_thinking_steps = []  # Initialize to prevent UnboundLocalError
        
        if request.cursor_mode and request.enable_intent_classification:
            # Yield initial analysis status
            yield {
                "type": "analysis_start",
                "content": "üéØ Analyzing request intent...",
                "provider": request.llm_provider,
                "status": "analyzing"
            }
            
            # Perform intent analysis with thoughts (returns raw thinking steps)
            request_analysis, raw_thinking_steps = await self.executive_tool._analyze_request_intent_with_thoughts(request)
            
            # Create orchestration plan
            orchestration_plan = self.executive_tool._create_tool_orchestration_plan(request, request_analysis)
            
            # Yield analysis results
            yield {
                "type": "analysis_complete",
                "content": f"üìä Intent: {request_analysis.intent} (confidence: {request_analysis.confidence:.2f})",
                "provider": request.llm_provider,
                "analysis": {
                    "intent": request_analysis.intent,
                    "confidence": request_analysis.confidence,
                    "complexity": request_analysis.complexity,
                    "suggested_tools": request_analysis.suggested_tools,
                    "reasoning": request_analysis.reasoning,
                    "thinking_steps": raw_thinking_steps
                },
                "orchestration_plan": orchestration_plan
            }
            
            # Brief pause for user to see analysis
            await asyncio.sleep(0.5)
        
        # NEW: Generate unified Cursor-style thoughts in correct logical order
        async for thought in self.executive_tool._generate_unified_cursor_thoughts(request, request_analysis, orchestration_plan, raw_thinking_steps):
            yield thought
        
        # NEW: Deep reasoning chain (when enabled) - MOVED TO CORRECT POSITION
        if request.enable_deep_reasoning and request.cursor_mode and request_analysis:
            yield {
                "type": "thinking",
                "content": "üß† Activating deep reasoning mode - I'll investigate your specific context before proposing solutions...",
                "thought_type": "deep_reasoning_start",
                "reasoning_step": "init",
                "timestamp": datetime.now().isoformat()
            }
            
            async for reasoning_chunk in self._execute_deep_reasoning_chain(request, request_analysis):
                yield reasoning_chunk
        
        # CRITICAL: Knowledge extraction BEFORE LLM response (for teaching scenarios)
        teaching_detected = await self._contains_teaching_content(request.user_query)
        logger.info(f"Teaching content detection result: {teaching_detected} for query: {request.user_query[:50]}...")
        if teaching_detected:
            yield {
                "type": "thinking",
                "content": f"üîç Teaching content detected in query: '{request.user_query[:50]}...' - Extracting actionable knowledge pieces from your input...",
                "thought_type": "knowledge_extraction",
                "timestamp": datetime.now().isoformat()
            }
            
            try:
                # Extract knowledge from USER INPUT using specialized method
                extracted_knowledge = await self.executive_tool._extract_user_input_knowledge(
                    request.user_query,
                    request
                )
                
                yield {
                    "type": "thinking",
                    "content": f"üîß Knowledge extraction completed. Found: {len(extracted_knowledge) if extracted_knowledge else 0} pieces",
                    "thought_type": "knowledge_debug",
                    "timestamp": datetime.now().isoformat()
                }
                
            except Exception as e:
                yield {
                    "type": "thinking",
                    "content": f"‚ùå Knowledge extraction failed: {str(e)}",
                    "thought_type": "knowledge_error",
                    "timestamp": datetime.now().isoformat()
                }
                extracted_knowledge = None
            
            if extracted_knowledge:
                yield {
                    "type": "thinking", 
                    "content": f"üîç Extracted {len(extracted_knowledge)} knowledge pieces from your input",
                    "thought_type": "knowledge_extracted",
                    "timestamp": datetime.now().isoformat()
                }
                
                # Stream knowledge approval request IMMEDIATELY
                async for approval_chunk in self.executive_tool._stream_knowledge_approval_request(extracted_knowledge, request):
                    yield approval_chunk
                
                # STOP HERE - Wait for human approval before any LLM response
                yield {
                    "type": "awaiting_approval",
                    "content": "‚è≥ Waiting for your approval on the knowledge pieces...",
                    "requires_human_input": True,
                    "timestamp": datetime.now().isoformat()
                }
                
                # EXIT - No LLM response until human approves
                yield {
                    "type": "thinking",
                    "content": "üõë STOPPING execution - waiting for human approval before any LLM response",
                    "thought_type": "execution_stopped",
                    "timestamp": datetime.now().isoformat()
                }
                return
            else:
                yield {
                    "type": "thinking",
                    "content": f"‚ö†Ô∏è No knowledge pieces extracted - continuing with normal response flow",
                    "thought_type": "no_knowledge",
                    "timestamp": datetime.now().isoformat()
                }
        
        # Get available tools for execution based on configuration
        tools_to_use = []
        has_learning_tools = False
        
        if request.enable_tools:
            # If we have an orchestration plan, use it to guide tool selection
            if orchestration_plan:
                primary_tools = orchestration_plan.get("primary_tools", [])
                secondary_tools = orchestration_plan.get("secondary_tools", [])
                
                # Override force_tools based on plan
                if orchestration_plan.get("force_tools"):
                    request.force_tools = True
                
                # Create whitelist based on orchestration plan
                orchestrated_tools = primary_tools + secondary_tools
                if orchestrated_tools:
                    # Combine with user whitelist if exists
                    if request.tools_whitelist:
                        orchestrated_tools = [t for t in orchestrated_tools if t in request.tools_whitelist]
                    request.tools_whitelist = orchestrated_tools
                
                if request.cursor_mode:
                    yield {
                        "type": "tool_orchestration",
                        "content": f"üîß Tool plan: {orchestration_plan['reasoning']}",
                        "provider": request.llm_provider,
                        "tools_planned": orchestrated_tools
                    }
            
            # Add search tool if available and whitelisted
            search_tool = self._get_search_tool(request.model)
            if search_tool:
                if request.tools_whitelist is None or "search" in request.tools_whitelist:
                    tools_to_use.append(search_tool)
            
            # Add context tool if available and whitelisted  
            if "context" in self.executive_tool.available_tools:
                if request.tools_whitelist is None or "context" in request.tools_whitelist:
                    tools_to_use.append(self.executive_tool.available_tools["context"])
            
            # Add brain vector tool if available and whitelisted
            if "brain_vector" in self.executive_tool.available_tools:
                if request.tools_whitelist is None or "brain_vector" in request.tools_whitelist:
                    tools_to_use.append(self.executive_tool.available_tools["brain_vector"])
                    if request.cursor_mode:
                        yield {
                            "type": "tools_loaded",
                            "content": "üß† Brain vector tool loaded - ready to access existing knowledge",
                            "provider": request.llm_provider,
                            "brain_access": True
                        }
            
            # Add learning tools if available and whitelisted (create on demand with user context)
            if "learning_factory" in self.executive_tool.available_tools:
                # Check if any learning tools are whitelisted
                learning_tool_names = [
                    "learning_search", "learning_analysis", "human_learning", 
                    "knowledge_preview", "knowledge_save",
                    "search_learning_context", "analyze_learning_opportunity",
                    "request_learning_decision", "preview_knowledge_save", "save_knowledge"
                ]
                
                should_add_learning_tools = (
                    request.tools_whitelist is None or 
                    any(name in request.tools_whitelist for name in learning_tool_names)
                )
                
                if should_add_learning_tools:
                    # Create learning tools once with user context
                    learning_tools = self.executive_tool.available_tools["learning_factory"].create_learning_tools(
                        user_id=request.user_id, 
                        org_id=request.org_id,
                        llm_provider=request.llm_provider,
                        model=request.model
                    )
                    # Add all learning tools to available tools
                    tools_to_use.extend(learning_tools)
                    has_learning_tools = True
                    
                    # CRITICAL FIX: Always force tools when learning tools are present
                    # This ensures learning workflow triggers regardless of intent classification
                    request.force_tools = True
                    
                    if request.cursor_mode:
                        yield {
                            "type": "tools_loaded",
                            "content": f"üìö Added {len(learning_tools)} learning tools",
                            "provider": request.llm_provider,
                            "tools_count": len(learning_tools)
                        }
                        yield {
                            "type": "learning_force_enabled", 
                            "content": "üö® Learning tools detected - forcing tool usage to ensure workflow triggers",
                            "provider": request.llm_provider,
                            "force_tools": True
                        }
        
        # Set custom system prompt if provided, otherwise use appropriate default
        if request.system_prompt and request.system_prompt != "general":
            base_system_prompt = request.system_prompt
            # If learning tools are available, append learning instructions to custom prompt
            if has_learning_tools:
                learning_instructions = """

CRITICAL LEARNING CAPABILITY: When users provide information, immediately use learning tools.

MANDATORY TOOL USAGE for company info, instructions, or teaching content:
‚úì search_learning_context - Check existing knowledge
‚úì analyze_learning_opportunity - Assess learning value  
‚úì request_learning_decision - Get approval to learn"""
                base_system_prompt += learning_instructions
                request.force_tools = True
        else:
            # CURSOR-STYLE COPILOT BEHAVIOR
            if has_learning_tools:
                base_system_prompt = """You are Ami, an intelligent copilot assistant similar to Cursor or GitHub Copilot.

COPILOT BEHAVIOR (NOT CHATBOT):
- Act like Cursor: Investigate ‚Üí Analyze ‚Üí Propose ‚Üí Wait for approval
- Provide structured plans and next steps, not conversational responses  
- After analysis, propose concrete actions and wait for user direction
- Be concise and action-oriented

RESPONSE STRUCTURE:
1. Brief acknowledgment
2. Propose 2-3 specific approaches/options
3. Ask which direction they want to take
4. Wait for their choice before proceeding

LEARNING CAPABILITY: When users share information, immediately use learning tools.

MANDATORY TOOL USAGE for company info, instructions, or teaching content:
‚úì search_learning_context - Check existing knowledge
‚úì analyze_learning_opportunity - Assess learning value
‚úì request_learning_decision - Get approval to learn"""
                request.force_tools = True
            elif tools_to_use:
                base_system_prompt = """You are Ami, an intelligent copilot assistant similar to Cursor.

COPILOT BEHAVIOR:
- Investigate ‚Üí Analyze ‚Üí Propose ‚Üí Wait for approval
- Provide structured plans, not conversational responses
- Be concise and action-oriented
- Propose specific options and wait for user choice"""
            else:
                base_system_prompt = """You are Ami, a helpful copilot assistant.

Act like Cursor: Analyze the request, propose structured approaches, and wait for user direction."""
        
        # Apply language detection to create language-aware prompt
        system_prompt = await self.executive_tool._detect_language_and_create_prompt(request, request.user_query, base_system_prompt)
        
        # Generate thoughts about response generation if in cursor mode
        if request.cursor_mode:
            has_tool_results = bool(tools_to_use)
            async for thought in self.executive_tool._generate_response_thoughts(request.llm_provider, has_tool_results):
                yield thought
        
        try:
            # Collect LLM response content for post-response learning analysis
            full_response_content = ""
            
            # Use the new streaming method from OpenAITool with system prompt and tool config
            async for chunk in openai_tool.process_with_tools_stream(
                request.user_query, 
                tools_to_use, 
                system_prompt,
                force_tools=request.force_tools,
                conversation_history=request.conversation_history,
                max_history_messages=request.max_history_messages,
                max_history_tokens=request.max_history_tokens
            ):
                # Collect response content for post-analysis
                if chunk.get("type") == "response_chunk" and "content" in chunk:
                    full_response_content += chunk.get("content", "")
                
                # Enhance chunk with analysis data if available
                if request.cursor_mode and request_analysis:
                    chunk["request_analysis"] = {
                        "intent": request_analysis.intent,
                        "confidence": request_analysis.confidence,
                        "complexity": request_analysis.complexity
                    }
                    if orchestration_plan:
                        chunk["orchestration_plan"] = orchestration_plan
                
                yield chunk
            
            # Knowledge extraction now happens BEFORE LLM response, so this section is removed
                    
        except Exception as e:
            yield {
                "type": "error",
                "content": f"Error with OpenAI API: {str(e)}",
                "complete": True
            }


class OpenAIToolWithCustomPrompt(OpenAITool):
    """Extended OpenAI tool that supports custom system prompts"""
    
    def process_with_tools_and_prompt(
        self, 
        user_query: str, 
        available_tools: List[Any], 
        system_prompt: str,
        model_params: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        Process user query with available tools using custom system prompt
        
        Args:
            user_query: The user's input query
            available_tools: List of available tool instances
            system_prompt: Custom system prompt
            model_params: Optional model parameters (temperature, max_tokens, etc.)
            
        Returns:
            Response from GPT-4 with tool execution results
        """
        
        # Define functions for OpenAI
        functions = []
        for tool in available_tools:
            functions.append({
                "type": "function",
                "function": {
                    "name": "search_google",
                    "description": "Search Google for information on any topic",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "query": {
                                "type": "string",
                                "description": "The search query to look up"
                            }
                        },
                        "required": ["query"]
                    }
                }
            })
        
        # Prepare model parameters
        call_params = {
            "model": self.model,
            "messages": [
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": user_query
                }
            ],
            "tools": functions,
            "tool_choice": "auto"
        }
        
        # Add optional parameters
        if model_params:
            if "temperature" in model_params:
                call_params["temperature"] = model_params["temperature"]
            if "max_tokens" in model_params:
                call_params["max_tokens"] = model_params["max_tokens"]
            if "top_p" in model_params:
                call_params["top_p"] = model_params["top_p"]
        
        try:
            # First API call to GPT-4
            response = self.client.chat.completions.create(**call_params)
            
            message = response.choices[0].message
            
            # Check if GPT-4 wants to use tools
            if message.tool_calls:
                return self._handle_tool_calls_with_prompt(
                    message, available_tools, user_query, system_prompt
                )
            else:
                return message.content
                
        except Exception as e:
            return f"Error with OpenAI API: {str(e)}"
    
    def _handle_tool_calls_with_prompt(
        self, 
        message: Any, 
        available_tools: List[Any], 
        original_query: str,
        system_prompt: str
    ) -> str:
        """Handle tool calls with custom system prompt"""
        
        messages = [
            {
                "role": "system",
                "content": system_prompt
            },
            {
                "role": "user",
                "content": original_query
            },
            message
        ]
        
        # Execute each tool call
        for tool_call in message.tool_calls:
            function_name = tool_call.function.name
            function_args = json.loads(tool_call.function.arguments)
            
            # Execute the tool
            if function_name == "search_google" and available_tools:
                search_tool = available_tools[0]  # First tool is search tool
                result = search_tool.search(function_args.get("query", ""))
                
                messages.append({
                    "tool_call_id": tool_call.id,
                    "role": "tool",
                    "name": function_name,
                    "content": result
                })
        
        # Send tool results back to GPT-4
        try:
            final_response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=10000  # Default to 10k tokens for longer responses
            )
            
            return final_response.choices[0].message.content
            
        except Exception as e:
            return f"Error processing tool results: {str(e)}" 