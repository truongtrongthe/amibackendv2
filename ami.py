from langchain_openai import ChatOpenAI
from knowledge import  retrieve_relevant_infov2 
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain.memory import ConversationBufferMemory
from langchain_community.chat_message_histories import ChatMessageHistory
import os
from langchain_openai import OpenAIEmbeddings
from pinecone import Pinecone, ServerlessSpec
import json
import logging
from typing import Dict, Any
from openai import OpenAI
logging.basicConfig(level=logging.INFO)

PINECONE_API_KEY = os.getenv("PINECONE_API_KEY", "")
PINECONE_ENV = "us-east-1"  # Check Pinecone console for your region
index_name = "ami-knowledge"
llm = ChatOpenAI(model="gpt-4o", streaming=True)
client = OpenAI()
prompt = PromptTemplate(
    input_variables=["history", "user_input", "products", "user_style", "sales_skills"],
    template="""
    üéØ **M·ª•c ti√™u**: Hi·ªÉu √Ω ƒë·ªãnh c·ªßa ng∆∞·ªùi d√πng v√† ph·∫£n h·ªìi m·ªôt c√°ch ph√π h·ª£p.

    1Ô∏è‚É£ **N·∫øu ng∆∞·ªùi d√πng ƒëang h·ªèi v·ªÅ s·∫£n ph·∫©m** ‚Üí D·ª±a v√†o th√¥ng tin s·∫£n ph·∫©m ƒë√£ t√¨m th·∫•y ({products}) ƒë·ªÉ t∆∞ v·∫•n ng·∫Øn g·ªçn, ƒë·ªß √Ω, c√≥ d·∫´n d·∫Øt h·ª£p l√Ω.  
    2Ô∏è‚É£ **N·∫øu ng∆∞·ªùi d√πng ƒëang h·ªèi v·ªÅ k·ªπ nƒÉng b√°n h√†ng** ‚Üí √Åp d·ª•ng k·ªπ nƒÉng ph√π h·ª£p t·ª´ ({sales_skills}) v√†o c√¢u tr·∫£ l·ªùi.  
    3Ô∏è‚É£ **N·∫øu ng∆∞·ªùi d√πng ƒëang tr√≤ chuy·ªán b√¨nh th∆∞·ªùng** ‚Üí Duy tr√¨ h·ªôi tho·∫°i m·ªôt c√°ch t·ª± nhi√™n, c√≥ th·ªÉ th√™m c√¢u h·ªèi g·ª£i m·ªü.  
    4Ô∏è‚É£ **Lu√¥n ph·∫£n h·ªìi theo phong c√°ch c·ªßa ng∆∞·ªùi d√πng tr∆∞·ªõc ƒë√¢y**: {user_style}  

    üìú **L·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán**:  
    {history}  

    üó£ **Tin nh·∫Øn t·ª´ ng∆∞·ªùi d√πng**:  
    "{user_input}"  

    ‚úçÔ∏è **Ph·∫£n h·ªìi c·ªßa AMI** (gi·ªØ phong c√°ch h·ªôi tho·∫°i ph√π h·ª£p):  
    """
)

#  chat_history = ChatMessageHistory()
chat_history = ChatMessageHistory()

memory = ConversationBufferMemory(
    chat_memory=chat_history,
    memory_key="history",  # REQUIRED in newer versions
    return_messages=True
)

def retrieve_product(user_input):
    """Retrieve relevant context from Pinecone and return a structured summary."""
    if user_input is None:
        return "Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p."  # Return an appropriate message if input is None

    retrieved_info = retrieve_relevant_infov2(user_input, top_k=3)

    if not retrieved_info:
        return "Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p."

    structured_summary = []
    for doc in retrieved_info:
        content = doc.get("content", "").strip()
        if content:
            structured_summary.append(content)
    return "\n\n".join(structured_summary) if structured_summary else "Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p."

pc = Pinecone(api_key=PINECONE_API_KEY)

# Check if index exists
existing_indexes = [i['name'] for i in pc.list_indexes()]
if index_name not in existing_indexes:
    pc.create_index(
        name=index_name,
        dimension=1536,  # Ensure this matches your model's output dimension
        metric="cosine",
        spec=ServerlessSpec(cloud="aws", region="us-east-1")
    )

def detect_customer_intent_dynamic(message: str) -> Dict[str, Any]:
    response = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[
            {"role": "system", "content": """You are an AI that detects customer intent and categorizes it into three main groups:
                1. general_conversation (e.g., greetings, small talk, general inquiries)
                2. sales_related (e.g., asking about price, product details, promotions)
                3. after_sales (e.g., warranty, support, returns, complaints)
                Return a JSON object with "intent", "intent_group", and optional "sub_intent" fields.
            """},
            {"role": "user", "content": f"Analyze intent from this message: {message}"}
        ]
    )
    intent_data = response.choices[0].message.content
    return eval(intent_data)  # Gi·∫£ s·ª≠ output l√† dictionary JSON
   
def ami_drive(user_message, user_context,company_goal,product_info):
    """
    X·ª≠ l√Ω tin nh·∫Øn t·ª´ ng∆∞·ªùi d√πng, x√°c ƒë·ªãnh m·ª•c ti√™u, t·∫°o Best_map v√† d·∫´n d·∫Øt h·ªôi tho·∫°i.
    """
    intent_data = detect_customer_intent_dynamic(user_message)
    intent = intent_data.get("intent", "unknown")
    intent_group = intent_data.get("intent_group", "general_conversation")  # M·∫∑c ƒë·ªãnh l√† giao ti·∫øp th√¥ng th∆∞·ªùng
    sub_intent = intent_data.get("sub_intent", None)
    print("intent_group in the ami_drive:", intent_group)
    if intent_group == "general_conversation":
        return handle_general_conversation(intent, sub_intent,user_message, user_context)

    elif intent_group == "sales_related":
        return handle_sales(user_message, user_context,company_goal,product_info)

    elif intent_group == "after_sales":
        return "Post-sales support"

    else:
        return "Xin l·ªói, t√¥i ch∆∞a hi·ªÉu r√µ c√¢u h·ªèi c·ªßa b·∫°n. B·∫°n c√≥ th·ªÉ n√≥i r√µ h∆°n kh√¥ng?"


def handle_general_conversation(intent, sub_intent, user_message, user_context):
    # L·∫•y th√¥ng tin kh√°ch h√†ng t·ª´ user_context
    customer_info = user_context.get("customer_info", {})
    chat_history = user_context.get("chat_history", "")

    # C·∫≠p nh·∫≠t l·ªãch s·ª≠ h·ªôi tho·∫°i
    chat_history += f"\nUser: {user_message}"
    user_context["chat_history"] = chat_history  

    # **Danh s√°ch th√¥ng tin c·∫ßn thu th·∫≠p**
    required_fields = ["name", "age", "occupation", "interests"]
    missing_fields = [field for field in required_fields if not customer_info.get(field)]

    # **Ch·ªâ h·ªèi t√™n n·∫øu th·∫≠t s·ª± ch∆∞a c√≥**
    if "name" in missing_fields:
        probing_prompt = f"""
        L·ªãch s·ª≠ h·ªôi tho·∫°i: {chat_history}
        Th√¥ng tin kh√°ch h√†ng hi·ªán c√≥: {customer_info}
        B·∫°n l√† m·ªôt tr·ª£ l√Ω AI. Kh√°ch h√†ng ch∆∞a cung c·∫•p t√™n. H√£y ƒë·∫∑t m·ªôt c√¢u h·ªèi l·ªãch s·ª± ƒë·ªÉ h·ªèi t√™n.
        """
        return llm.invoke(probing_prompt).content

    # **N·∫øu ƒë√£ c√≥ t√™n nh∆∞ng c√≤n thi·∫øu th√¥ng tin kh√°c ‚Üí H·ªèi ti·∫øp th√¥ng tin c√≤n thi·∫øu**
    if missing_fields:
        probing_prompt = f"""
        L·ªãch s·ª≠ h·ªôi tho·∫°i: {chat_history}
        Th√¥ng tin kh√°ch h√†ng hi·ªán c√≥: {customer_info}
        Th√¥ng tin c√≤n thi·∫øu: {missing_fields}
        H√£y ƒë·∫∑t m·ªôt c√¢u h·ªèi t·ª± nhi√™n ƒë·ªÉ khai th√°c m·ªôt trong c√°c th√¥ng tin c√≤n thi·∫øu m√† kh√¥ng l√†m kh√°ch h√†ng kh√≥ ch·ªãu.
        """
        return llm.invoke(probing_prompt).content

    # **N·∫øu ƒë√£ c√≥ ƒë·ªß th√¥ng tin ‚Üí Tr·∫£ l·ªùi theo ng·ªØ c·∫£nh**
    response_prompt = f"""
    T√≥m t·∫Øt h·ªôi tho·∫°i: {chat_history}
    Th√¥ng tin kh√°ch h√†ng: {customer_info}
    C√¢u kh√°ch h√†ng v·ª´a h·ªèi: {user_message}
    H√£y ph·∫£n h·ªìi m·ªôt c√°ch t·ª± nhi√™n, ph√π h·ª£p v·ªõi th√¥ng tin kh√°ch h√†ng, gi·ªØ cu·ªôc tr√≤ chuy·ªán m∆∞·ª£t m√†.
    """
    extract_prompt = f"""
    H·ªôi tho·∫°i: {chat_history}
    Th√¥ng tin hi·ªán c√≥: {user_context.get("customer_info", {})}
    H√£y c·∫≠p nh·∫≠t th√¥ng tin kh√°ch h√†ng d·ª±a tr√™n h·ªôi tho·∫°i m·ªõi. 
    Ch√∫ √Ω: N·∫øu ƒë√£ c√≥ th√¥ng tin, kh√¥ng ƒë∆∞·ª£c l√†m m·∫•t th√¥ng tin c≈©. Ch·ªâ b·ªï sung ph·∫ßn c√≤n thi·∫øu.
    """

    return llm.invoke(response_prompt).content


def handle_sales(user_message, user_context,company_goal,product_info):
    """
    X·ª≠ l√Ω tin nh·∫Øn t·ª´ ng∆∞·ªùi d√πng, x√°c ƒë·ªãnh m·ª•c ti√™u, t·∫°o Best_map v√† d·∫´n d·∫Øt h·ªôi tho·∫°i.
    """
    # B∆∞·ªõc 1: L·∫•y th√¥ng tin kh√°ch h√†ng t·ª´ user_context
    customer_info = user_context.get("customer_info", {})
    chat_history = user_context.get("chat_history", "")
    chat_history += f"\nUser: {user_message}"
    user_context["chat_history"] = chat_history  # C·∫≠p nh·∫≠t l·ªãch s·ª≠ h·ªôi tho·∫°i
    
    # B∆∞·ªõc 2: X√°c ƒë·ªãnh customer_stage t·ª´ l·ªãch s·ª≠ h·ªôi tho·∫°i
    customer_stage = get_customer_stage(chat_history)
    user_context["customer_stage"] = customer_stage
    print("customer_stage:", customer_stage)

    # B∆∞·ªõc 3: X√°c ƒë·ªãnh m·ª•c ti√™u h·ªôi tho·∫°i
    cg = get_conversation_goal(customer_info, user_message, customer_stage)
    print("conversation_goal in handle_user_message:", cg)

    # B∆∞·ªõc 3: C·∫≠p nh·∫≠t customer_info v·ªõi customer_stage
    customer_info["customer_stage"] = customer_stage
    # B∆∞·ªõc 4: T·∫°o Best_map
    best_map = create_best_map(cg, customer_info,company_goal,product_info)
    print("best_map in handle_user_message:", best_map)

    response = generate_response(best_map, company_goal, customer_info)
    return response

def get_customer_stage(chat_history, company_goal="kh√°ch chuy·ªÉn kho·∫£n"):
    """
    D√πng LLM ƒë·ªÉ x√°c ƒë·ªãnh giai ƒëo·∫°n c·ªßa kh√°ch h√†ng d·ª±a tr√™n l·ªãch s·ª≠ h·ªôi tho·∫°i.
    """
    prompt = f"""
    B·∫°n l√† m·ªôt AI t∆∞ v·∫•n b√°n h√†ng. D∆∞·ªõi ƒë√¢y l√† l·ªãch s·ª≠ h·ªôi tho·∫°i gi·ªØa nh√¢n vi√™n v√† kh√°ch h√†ng:
    {chat_history}
    
    C√¥ng ty c√≥ m·ª•c ti√™u cu·ªëi c√πng l√† '{company_goal}'.
    D·ª±a v√†o l·ªãch s·ª≠ h·ªôi tho·∫°i, h√£y x√°c ƒë·ªãnh kh√°ch h√†ng ƒëang ·ªü giai ƒëo·∫°n n√†o trong h√†nh tr√¨nh n√†y:
    - Awareness (Nh·∫≠n th·ª©c)
    - Interest (Quan t√¢m)
    - Consideration (C√¢n nh·∫Øc)
    - Decision (Quy·∫øt ƒë·ªãnh)
    - Action (Chuy·ªÉn kho·∫£n)
    
    Ch·ªâ tr·∫£ v·ªÅ m·ªôt trong c√°c giai ƒëo·∫°n tr√™n m√† kh√¥ng c√≥ b·∫•t k·ª≥ gi·∫£i th√≠ch n√†o.
    """

    response= llm.invoke(prompt).content
    return response.strip()


def get_customer_emotion(chat_history):
   
    prompt = f"""
    B·∫°n l√† m·ªôt chuy√™n gia t√¢m l√Ω tinh t·∫ø. H√£y ph√°t hi·ªán c·∫£m x√∫c hi·ªán t·∫°i c·ªßa kh√°ch h√†ng d·ª±a tr√™n l·ªãch s·ª≠ h·ªôi tho·∫°i:
    {chat_history}
    Ch·ªâ tr·∫£ v·ªÅ tr·∫°ng th√°i c·∫£m x√∫c m√† kh√¥ng gi·∫£i th√≠ch th√™m
    """
    response= llm.invoke(prompt).content
    return response.strip()

def get_customer_info(chat_history, user_context):
    print("chat_history in the extract_customer_info:", chat_history)
    
    """
    D√πng LLM ƒë·ªÉ ph√¢n t√≠ch l·ªãch s·ª≠ h·ªôi tho·∫°i v√† tr√≠ch xu·∫•t th√¥ng tin kh√°ch h√†ng.
    """
    
    # L·∫•y th√¥ng tin kh√°ch h√†ng ƒë√£ c√≥
    existing_info = user_context.get("customer_info", {})

    extract_prompt = f"""
    H·ªôi tho·∫°i gi·ªØa AI v√† kh√°ch h√†ng:
        {chat_history}

        Th√¥ng tin kh√°ch h√†ng ƒë√£ c√≥: {user_context.get("customer_info", {})}

        H√£y **ch·ªâ tr·∫£ v·ªÅ JSON thu·∫ßn** v·ªõi ƒë·ªãnh d·∫°ng sau:
        ```json
        {{
            "name": "...",
            "age": "...",
            "gender": "...",
            "occupation": "...",
            "interests": [...],
            "purchase_history": [...]
        }}```
    """

    # G·ªçi LLM ƒë·ªÉ ph√¢n t√≠ch th√¥ng tin
    response = llm.invoke(extract_prompt).content  
    print("Raw response from LLM:", response)


    try:
        # L√†m s·∫°ch chu·ªói JSON n·∫øu c√≥ d·∫•u ```json ho·∫∑c ``` th·ª´a
        json_start = response.find("{")
        json_end = response.rfind("}") + 1
        clean_json = response[json_start:json_end]

        # Parse JSON
        extracted_info = json.loads(clean_json)
        print("Extracted customer info:", extracted_info)

        # H·ª£p nh·∫•t d·ªØ li·ªáu c≈© v·ªõi d·ªØ li·ªáu m·ªõi
        updated_info = existing_info.copy()

        for key, value in extracted_info.items():
            if value:  # Ch·ªâ c·∫≠p nh·∫≠t n·∫øu c√≥ gi√° tr·ªã
                if key == "interests" and isinstance(value, list):
                    updated_info.setdefault("interests", []).extend(value)  # Th√™m v√†o danh s√°ch c≈©
                    updated_info["interests"] = list(set(updated_info["interests"]))  # Lo·∫°i b·ªè tr√πng l·∫∑p
                else:
                    updated_info[key] = value  # C·∫≠p nh·∫≠t c√°c tr∆∞·ªùng kh√°c

        return updated_info

    except json.JSONDecodeError as e:
        print("JSON decoding error:", e)
        return existing_info  # Tr·∫£ v·ªÅ d·ªØ li·ªáu c≈© n·∫øu g·∫∑p l·ªói

def update_customer_info(user_context, extracted_info):
    """ C·∫≠p nh·∫≠t th√¥ng tin kh√°ch h√†ng b·∫±ng c√°ch h·ª£p nh·∫•t d·ªØ li·ªáu m·ªõi v√†o d·ªØ li·ªáu c≈© """
    if "customer_info" not in user_context:
        user_context["customer_info"] = {}

    for key, value in extracted_info.items():
        if value:  # Ch·ªâ c·∫≠p nh·∫≠t n·∫øu c√≥ d·ªØ li·ªáu m·ªõi
            if isinstance(user_context["customer_info"].get(key), list):
                if value not in user_context["customer_info"][key]:
                    user_context["customer_info"][key].append(value)  # Th√™m v√†o danh s√°ch
            else:
                user_context["customer_info"][key] = value  # Ghi ƒë√® gi√° tr·ªã m·ªõi


def get_conversation_goal(customer_info, user_message, customer_stage):
    """
    X√°c ƒë·ªãnh m·ª•c ti√™u h·ªôi tho·∫°i d·ª±a tr√™n th√¥ng tin kh√°ch h√†ng, n·ªôi dung tin nh·∫Øn v√† giai ƒëo·∫°n kh√°ch h√†ng.
    """
    print("user_message in the determine_conversation_goal:", user_message)
    print("customer_info in the determine_conversation_goal:", customer_info)
    print("customer_stage in the determine_conversation_goal:", customer_stage)

    # N·∫øu th√¥ng tin kh√°ch c√≤n thi·∫øu, c·∫ßn ti·∫øp t·ª•c h·ªèi ƒë·ªÉ ho√†n ch·ªânh
    if "missing_fields" in customer_info and len(customer_info["missing_fields"]) > 0:
        return "Kh·ªüi t·∫°o h·ªôi tho·∫°i chung"

    # X√°c ƒë·ªãnh m·ª•c ti√™u ti·∫øp theo b·∫±ng c√°ch suy lu·∫≠n t·ª´ company_goal
    prompt = f"""
    D·ª±a tr√™n giai ƒëo·∫°n kh√°ch h√†ng trong h√†nh tr√¨nh mua h√†ng: "{customer_stage}", 
    v√† tin nh·∫Øn: "{user_message}", h√£y x√°c ƒë·ªãnh b∆∞·ªõc h·ª£p l√Ω ti·∫øp theo ƒë·ªÉ d·∫´n kh√°ch h√†ng ƒë·∫øn m·ª•c ti√™u "Chuy·ªÉn kho·∫£n".
    
    Tr·∫£ v·ªÅ ch·ªâ m·ªôt m·ª•c ti√™u h·ªôi tho·∫°i c·ª• th·ªÉ (kh√¥ng gi·∫£i th√≠ch), v√≠ d·ª•: "Gi·ªõi thi·ªáu s·∫£n ph·∫©m", "Thuy·∫øt ph·ª•c kh√°ch h√†ng", "H∆∞·ªõng d·∫´n thanh to√°n".
    """

    response = llm.invoke(prompt).content  # G·ªçi LLM ƒë·ªÉ ph√¢n t√≠ch


    return response.strip()

def create_best_map(conversation_goal, customer_info, company_goal, product_info):
    """
    S·ª≠ d·ª•ng LLM ƒë·ªÉ suy lu·∫≠n Best_map ph√π h·ª£p d·ª±a tr√™n conversation_goal, customer_info v√† company_goal.
    """
    prompt = f"""
    üõí Kh√°ch h√†ng ƒëang ·ªü giai ƒëo·∫°n: "{customer_info.get('customer_stage', 'Unknown')}"
    üéØ M·ª•c ti√™u h·ªôi tho·∫°i: "{conversation_goal}"
    üèÜ M·ª•c ti√™u cu·ªëi c√πng c·ªßa c√¥ng ty: "{company_goal}"
    üë§ Th√¥ng tin kh√°ch h√†ng: {customer_info}
    üì¶ Th√¥ng tin s·∫£n ph·∫©m c√¥ng ty: {product_info}

    ‚úÖ H√£y t·∫°o m·ªôt h∆∞·ªõng d·∫´n ph·∫£n h·ªìi t·ªët nh·∫•t (Best_map) gi√∫p nh√¢n vi√™n b√°n h√†ng n√≥i chuy·ªán h·ª£p l√Ω v√† h∆∞·ªõng kh√°ch h√†ng ƒë·∫øn {company_goal}.
    ‚úÖ ƒêi·ªÅu ch·ªânh ph·∫£n h·ªìi d·ª±a tr√™n c·∫£m x√∫c v√† giai ƒëo·∫°n c·ªßa kh√°ch h√†ng:
    - N·∫øu ch∆∞a bi·∫øt t√™n kh√°ch h√†ng, h√£y h·ªèi t√™n kh√°ch h√†ng tr∆∞·ªõc.
    - N·∫øu kh√°ch h√†ng c√≤n ph√¢n v√¢n, h√£y nh·∫•n m·∫°nh l·ª£i √≠ch c·ªßa s·∫£n ph·∫©m.
    - N·∫øu kh√°ch h√†ng c√≥ h·ª©ng th√∫, h√£y g·ª£i m·ªü m·ªôt l√Ω do m·∫°nh m·∫Ω ƒë·ªÉ h√†nh ƒë·ªông ngay.
    - N·∫øu kh√°ch h√†ng c√≥ lo ng·∫°i, h√£y tr·∫•n an v√† cung c·∫•p th√¥ng tin h·ªó tr·ª£.

    üé§ N·∫øu bi·∫øt t√™n kh√°ch h√†ng, h√£y x∆∞ng h√¥ th√¢n thi·ªán.
    üì¢ Tr·∫£ v·ªÅ m·ªôt ƒëo·∫°n vƒÉn ng·∫Øn, kh√¥ng qu√° 3 c√¢u, v·ªõi phong c√°ch giao ti·∫øp th∆∞·ªùng th·ª©c (casual).
    """
    response = llm.invoke(prompt).content  # G·ªçi OpenAI ho·∫∑c m√¥ h√¨nh AI kh√°c
    return response.strip()


def search_sales_skills(query_text, max_skills=3):
    """ 
    Truy v·∫•n k·ªπ nƒÉng t·ª´ Pinecone v·ªõi ƒë·ªô ch√≠nh x√°c cao h∆°n. 
    """
    embedding_model = OpenAIEmbeddings(model="text-embedding-3-large", dimensions=1536)
    query_embedding = embedding_model.embed_query(query_text)

    index = pc.Index(index_name)
    response = index.query(
        vector=query_embedding,
        top_k=max_skills,
        include_metadata=True  
    )

    skills = []
    if response and "matches" in response:
        for match in response["matches"]:
            skill_text = match.get("metadata", {}).get("content")
            if skill_text:
                skills.append(skill_text)

    return skills if skills else ["Kh√¥ng t√¨m th·∫•y k·ªπ nƒÉng ph√π h·ª£p."]



chain = (
    RunnablePassthrough.assign(
        history=lambda _: memory.load_memory_variables({}).get("history", []),
        products=lambda x: retrieve_product(x["user_input"]),
        sales_skills=lambda x: ", ".join(search_sales_skills(x["user_input"], max_skills=3)),  # L·∫•y k·ªπ nƒÉng t·ª´ Pinecone
        user_style=lambda _: "l·ªãch s·ª±"
    )  
    | prompt
    | llm
)
def ami_selling(user_message, user_context=None):
    """
    H√†m ch√≠nh x·ª≠ l√Ω h·ªôi tho·∫°i b√°n h√†ng c·ªßa Ami.
    """
    if user_context is None:
        user_context = {}

    print("user_message in the ami_selling:", user_message)

    # Tr√≠ch xu·∫•t th√¥ng tin kh√°ch h√†ng v√† c·∫≠p nh·∫≠t v√†o user_context
    extracted_info = get_customer_info(user_message, user_context)
    print("extracted_info in the ami_selling:", extracted_info)

    if "customer_info" not in user_context:
        user_context["customer_info"] = {}

    # C·∫≠p nh·∫≠t user_context v·ªõi th√¥ng tin m·ªõi (kh√¥ng ghi ƒë√® gi√° tr·ªã c≈©)
    for key, value in extracted_info.items():
        if value:  # Ch·ªâ c·∫≠p nh·∫≠t n·∫øu c√≥ gi√° tr·ªã
            if key == "interests" and isinstance(value, list):
                user_context["customer_info"].setdefault("interests", []).extend(value)
                user_context["customer_info"]["interests"] = list(set(user_context["customer_info"]["interests"]))  # Lo·∫°i b·ªè tr√πng l·∫∑p
            else:
                user_context["customer_info"][key] = value

    print("Updated user_context:", user_context)

    company_goal = "Kh√°ch chuy·ªÉn kho·∫£n"
    product_info = retrieve_product(user_message)

    # G·ªçi ami_drive ƒë·ªÉ l·∫•y ph·∫£n h·ªìi ch√≠nh
    response = ami_drive(user_message, user_context, company_goal, product_info)

    return response


def generate_response(best_map, company_goal, customer_info):
    """
    Sinh ph·∫£n h·ªìi d·ª±a tr√™n Best_map + h∆∞·ªõng kh√°ch h√†ng ƒë·∫øn company_goal.
    """
    prompt = f"""
    Kh√°ch h√†ng: {customer_info}
    Best_map: "{best_map}"
    Company_goal: "{company_goal}"

    H√£y t·∫°o m·ªôt ph·∫£n h·ªìi t·ª± nhi√™n, th√¢n thi·ªán, d·∫´n d·∫Øt kh√°ch h√†ng theo Best_map v√† h∆∞·ªõng h·ªç ƒë·∫øn {company_goal}.
    """

    response = llm.invoke(prompt).content  # G·ªçi OpenAI ho·∫∑c m√¥ h√¨nh AI kh√°c ƒë·ªÉ sinh ph·∫£n h·ªìi
    return response.strip()