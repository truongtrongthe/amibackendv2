from langchain_openai import ChatOpenAI
from Archived.knowledge import  retrieve_relevant_infov2 
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain.memory import ConversationBufferMemory
from langchain_community.chat_message_histories import ChatMessageHistory
import os
from langchain_openai import OpenAIEmbeddings
from pinecone import Pinecone, ServerlessSpec
import json
import logging
from openai import OpenAI
logging.basicConfig(level=logging.INFO)

PINECONE_API_KEY = os.getenv("PINECONE_API_KEY", "")
PINECONE_ENV = "us-east-1"  # Check Pinecone console for your region
index_name = "ami-knowledge"
llm = ChatOpenAI(model="gpt-4o", streaming=True)

prompt = PromptTemplate(
    input_variables=["history", "user_input", "products", "user_style", "sales_skills"],
    template="""
    ğŸ¯ **Má»¥c tiÃªu**: Hiá»ƒu Ã½ Ä‘á»‹nh cá»§a ngÆ°á»i dÃ¹ng vÃ  pháº£n há»“i má»™t cÃ¡ch phÃ¹ há»£p.

    1ï¸âƒ£ **Náº¿u ngÆ°á»i dÃ¹ng Ä‘ang há»i vá» sáº£n pháº©m** â†’ Dá»±a vÃ o thÃ´ng tin sáº£n pháº©m Ä‘Ã£ tÃ¬m tháº¥y ({products}) Ä‘á»ƒ tÆ° váº¥n ngáº¯n gá»n, Ä‘á»§ Ã½, cÃ³ dáº«n dáº¯t há»£p lÃ½.  
    2ï¸âƒ£ **Náº¿u ngÆ°á»i dÃ¹ng Ä‘ang há»i vá» ká»¹ nÄƒng bÃ¡n hÃ ng** â†’ Ãp dá»¥ng ká»¹ nÄƒng phÃ¹ há»£p tá»« ({sales_skills}) vÃ o cÃ¢u tráº£ lá»i.  
    3ï¸âƒ£ **Náº¿u ngÆ°á»i dÃ¹ng Ä‘ang trÃ² chuyá»‡n bÃ¬nh thÆ°á»ng** â†’ Duy trÃ¬ há»™i thoáº¡i má»™t cÃ¡ch tá»± nhiÃªn, cÃ³ thá»ƒ thÃªm cÃ¢u há»i gá»£i má»Ÿ.  
    4ï¸âƒ£ **LuÃ´n pháº£n há»“i theo phong cÃ¡ch cá»§a ngÆ°á»i dÃ¹ng trÆ°á»›c Ä‘Ã¢y**: {user_style}  

    ğŸ“œ **Lá»‹ch sá»­ cuá»™c trÃ² chuyá»‡n**:  
    {history}  

    ğŸ—£ **Tin nháº¯n tá»« ngÆ°á»i dÃ¹ng**:  
    "{user_input}"  

    âœï¸ **Pháº£n há»“i cá»§a AMI** (giá»¯ phong cÃ¡ch há»™i thoáº¡i phÃ¹ há»£p):  
    """
)

#  chat_history = ChatMessageHistory()
chat_history = ChatMessageHistory()

memory = ConversationBufferMemory(
    chat_memory=chat_history,
    memory_key="history",  # REQUIRED in newer versions
    return_messages=True
)

def retrieve_product(user_input):
    """Retrieve relevant context from Pinecone and return a structured summary."""
    if user_input is None:
        return "KhÃ´ng tÃ¬m tháº¥y sáº£n pháº©m phÃ¹ há»£p."  # Return an appropriate message if input is None

    retrieved_info = retrieve_relevant_infov2(user_input, top_k=10)

    if not retrieved_info:
        return "KhÃ´ng tÃ¬m tháº¥y sáº£n pháº©m phÃ¹ há»£p."

    structured_summary = []
    for doc in retrieved_info:
        content = doc.get("content", "").strip()
        if content:
            structured_summary.append(content)
    return "\n\n".join(structured_summary) if structured_summary else "KhÃ´ng tÃ¬m tháº¥y sáº£n pháº©m phÃ¹ há»£p."

pc = Pinecone(api_key=PINECONE_API_KEY)

# Check if index exists
existing_indexes = [i['name'] for i in pc.list_indexes()]
if index_name not in existing_indexes:
    pc.create_index(
        name=index_name,
        dimension=1536,  # Ensure this matches your model's output dimension
        metric="cosine",
        spec=ServerlessSpec(cloud="aws", region="us-east-1")
    )


def handle_user_message(user_message, user_context,company_goal,product_info):
    """
    Xá»­ lÃ½ tin nháº¯n tá»« ngÆ°á»i dÃ¹ng, xÃ¡c Ä‘á»‹nh má»¥c tiÃªu, táº¡o Best_map vÃ  dáº«n dáº¯t há»™i thoáº¡i.
    """
    # BÆ°á»›c 1: Láº¥y thÃ´ng tin khÃ¡ch hÃ ng tá»« user_context
    customer_info = user_context.get("customer_info", {})
    chat_history = user_context.get("chat_history", "")
    chat_history += f"\nUser: {user_message}"
    user_context["chat_history"] = chat_history  # Cáº­p nháº­t lá»‹ch sá»­ há»™i thoáº¡i

    # BÆ°á»›c 2: XÃ¡c Ä‘á»‹nh customer_stage tá»« lá»‹ch sá»­ há»™i thoáº¡i
    customer_stage = get_customer_stage(chat_history)
    user_context["customer_stage"] = customer_stage
    print("customer_stage:", customer_stage)

    # BÆ°á»›c 3: XÃ¡c Ä‘á»‹nh má»¥c tiÃªu há»™i thoáº¡i
    conversation_goal = determine_conversation_goal(customer_info, user_message, customer_stage)
    print("conversation_goal in handle_user_message:", conversation_goal)

    # BÆ°á»›c 3: Cáº­p nháº­t customer_info vá»›i customer_stage
    customer_info["customer_stage"] = customer_stage
    # BÆ°á»›c 4: Táº¡o Best_map
    best_map = create_best_map(conversation_goal, customer_info,company_goal,product_info)
    print("best_map in handle_user_message:", best_map)

    response = generate_response(best_map, company_goal, customer_info)
    return response


def get_customer_stage(chat_history, company_goal="khÃ¡ch chuyá»ƒn khoáº£n"):
    """
    DÃ¹ng LLM Ä‘á»ƒ xÃ¡c Ä‘á»‹nh giai Ä‘oáº¡n cá»§a khÃ¡ch hÃ ng dá»±a trÃªn lá»‹ch sá»­ há»™i thoáº¡i.
    """
    prompt = f"""
    Báº¡n lÃ  má»™t AI tÆ° váº¥n bÃ¡n hÃ ng. DÆ°á»›i Ä‘Ã¢y lÃ  lá»‹ch sá»­ há»™i thoáº¡i giá»¯a nhÃ¢n viÃªn vÃ  khÃ¡ch hÃ ng:
    {chat_history}
    
    CÃ´ng ty cÃ³ má»¥c tiÃªu cuá»‘i cÃ¹ng lÃ  '{company_goal}'.
    Dá»±a vÃ o lá»‹ch sá»­ há»™i thoáº¡i, hÃ£y xÃ¡c Ä‘á»‹nh khÃ¡ch hÃ ng Ä‘ang á»Ÿ giai Ä‘oáº¡n nÃ o trong hÃ nh trÃ¬nh nÃ y:
    - Awareness (Nháº­n thá»©c)
    - Interest (Quan tÃ¢m)
    - Consideration (CÃ¢n nháº¯c)
    - Decision (Quyáº¿t Ä‘á»‹nh)
    - Action (Chuyá»ƒn khoáº£n)
    
    Chá»‰ tráº£ vá» má»™t trong cÃ¡c giai Ä‘oáº¡n trÃªn mÃ  khÃ´ng cÃ³ báº¥t ká»³ giáº£i thÃ­ch nÃ o.
    """

    response= llm.invoke(prompt).content
    return response.strip()


def get_customer_emotion(chat_history):
   
    prompt = f"""
    Báº¡n lÃ  má»™t chuyÃªn gia tÃ¢m lÃ½ tinh táº¿. HÃ£y phÃ¡t hiá»‡n cáº£m xÃºc hiá»‡n táº¡i cá»§a khÃ¡ch hÃ ng dá»±a trÃªn lá»‹ch sá»­ há»™i thoáº¡i:
    {chat_history}
    Chá»‰ tráº£ vá» tráº¡ng thÃ¡i cáº£m xÃºc mÃ  khÃ´ng giáº£i thÃ­ch thÃªm
    """
    response= llm.invoke(prompt).content
    return response.strip()

def extract_customer_info(chat_history):
    print("chat_history in the extract_customer_info:", chat_history)
    """
    DÃ¹ng LLM Ä‘á»ƒ phÃ¢n tÃ­ch lá»‹ch sá»­ há»™i thoáº¡i vÃ  trÃ­ch xuáº¥t thÃ´ng tin khÃ¡ch hÃ ng.
    """
    prompt = f"""
    DÆ°á»›i Ä‘Ã¢y lÃ  lá»‹ch sá»­ há»™i thoáº¡i giá»¯a AI vÃ  khÃ¡ch hÃ ng:
    {chat_history}

    Dá»±a vÃ o ná»™i dung nÃ y, hÃ£y trÃ­ch xuáº¥t cÃ¡c thÃ´ng tin sau (náº¿u cÃ³):
    - TÃªn khÃ¡ch hÃ ng (name)
    - Tuá»•i (age)
    - Giá»›i tÃ­nh (gender)
    - Nghá» nghiá»‡p (occupation)
    - Sá»Ÿ thÃ­ch (interests)
    - Lá»‹ch sá»­ mua hÃ ng (purchase_history)

    Tráº£ vá» má»™t JSON vá»›i cÃ¡c trÆ°á»ng tÆ°Æ¡ng á»©ng.
    Náº¿u khÃ´ng cÃ³ thÃ´ng tin, Ä‘á»ƒ trá»‘ng.
    """

    response = llm.invoke(prompt).content  # Gá»i LLM Ä‘á»ƒ phÃ¢n tÃ­ch

    try:
        # LÃ m sáº¡ch chuá»—i JSON náº¿u cÃ³ dáº¥u ```json hoáº·c ``` thá»«a
        json_start = response.find("{")
        json_end = response.rfind("}") + 1
        clean_json = response[json_start:json_end]

        # Parse JSON
        extracted_info = json.loads(clean_json)
        print("Extracted customer info:", extracted_info)

        return extracted_info
    except json.JSONDecodeError as e:
        print("JSON decoding error:", e)
        return {}

def update_customer_info(current_info, new_info):
    """
    Cáº­p nháº­t thÃ´ng tin khÃ¡ch hÃ ng vá»›i dá»¯ liá»‡u má»›i.
    """
    for key, value in new_info.items():
        if value:  # Chá»‰ cáº­p nháº­t náº¿u cÃ³ thÃ´ng tin má»›i
            current_info[key] = value
    
    # Kiá»ƒm tra náº¿u váº«n cÃ²n missing fields
    missing_fields = [key for key, value in current_info.items() if not value]
    if missing_fields:
        current_info["status"] = "missing_info"
        current_info["missing_fields"] = missing_fields
    else:
        current_info["status"] = "completed"

    return current_info

def chat_pipeline(user_message, chat_history, customer_info, llm):
    """
    Xá»­ lÃ½ há»™i thoáº¡i theo pipeline:
    1. TrÃ­ch xuáº¥t thÃ´ng tin khÃ¡ch hÃ ng
    2. Cáº­p nháº­t customer_info
    3. Tiáº¿p tá»¥c há»™i thoáº¡i dá»±a trÃªn tÃ¬nh tráº¡ng customer_info
    """
    # 1. TrÃ­ch xuáº¥t thÃ´ng tin tá»« lá»‹ch sá»­ chat
    new_info = extract_customer_info(chat_history, llm)
    print("new_info:", new_info)

    # 2. Cáº­p nháº­t thÃ´ng tin khÃ¡ch hÃ ng
    customer_info = update_customer_info(customer_info, new_info)
    print("customer_info:", customer_info)
    # 3. Kiá»ƒm tra xem Ä‘Ã£ Ä‘á»§ thÃ´ng tin chÆ°a
    if customer_info["status"] == "missing_info":
        missing = customer_info["missing_fields"]
        next_question = ask_for_missing_info(missing)
        return next_question, customer_info
    
    # 4. Náº¿u Ä‘Ã£ Ä‘á»§ thÃ´ng tin, tiáº¿p tá»¥c há»™i thoáº¡i
    response = continue_conversation(user_message, customer_info, llm)
    return response, customer_info
def ask_for_missing_info(missing_fields):
    """
    Sinh cÃ¢u há»i Ä‘á»ƒ tiáº¿p tá»¥c hoÃ n thiá»‡n thÃ´ng tin khÃ¡ch hÃ ng.
    """
    questions = {
        "name": "Báº¡n cÃ³ thá»ƒ cho tÃ´i biáº¿t tÃªn cá»§a báº¡n khÃ´ng?",
        "age": "Báº¡n bao nhiÃªu tuá»•i?",
        "gender": "Báº¡n lÃ  nam hay ná»¯?",
        "occupation": "Báº¡n Ä‘ang lÃ m nghá» gÃ¬?",
        "interests": "Báº¡n quan tÃ¢m Ä‘áº¿n lÄ©nh vá»±c nÃ o?",
        "purchase_history": "Báº¡n Ä‘Ã£ tá»«ng mua sáº£n pháº©m nÃ o tÆ°Æ¡ng tá»± chÆ°a?"
    }
    for field in missing_fields:
        if field in questions:
            return questions[field]  # Há»i láº§n lÆ°á»£t tá»«ng cÃ¢u
    return "HÃ£y cho tÃ´i biáº¿t thÃªm vá» báº¡n!"  # Náº¿u khÃ´ng cÃ³ cÃ¢u há»i cá»¥ thá»ƒ
def continue_conversation(user_message, customer_info, llm):
    """
    Tiáº¿p tá»¥c há»™i thoáº¡i dá»±a trÃªn thÃ´ng tin khÃ¡ch hÃ ng vÃ  má»¥c tiÃªu há»™i thoáº¡i.
    """
    conversation_goal = determine_conversation_goal(user_message, customer_info)
    
    best_map = create_best_map(conversation_goal, customer_info)
    
    response = llm.generate(f"Dá»±a vÃ o má»¥c tiÃªu '{conversation_goal}', hÃ£y pháº£n há»“i: {user_message}")
    
    return response


def determine_conversation_goal_hardcoded(customer_info, user_message, customer_stage):
    """
    XÃ¡c Ä‘á»‹nh má»¥c tiÃªu há»™i thoáº¡i dá»±a trÃªn Ä‘iá»ƒm hiá»‡n táº¡i (customer_stage) vÃ  má»¥c tiÃªu tiáº¿p theo.
    """
    print("user_message in the determine_conversation_goal:", user_message)
    print("customer_info in the determine_conversation_goal:", customer_info)
    print("customer_stage in the determine_conversation_goal:", customer_stage)

    if "missing_fields" in customer_info and len(customer_info["missing_fields"]) > 0:
        return "Khá»Ÿi táº¡o há»™i thoáº¡i chung"

    # XÃ¡c Ä‘á»‹nh "Ä‘iá»ƒm B" dá»±a trÃªn hÃ nh trÃ¬nh khÃ¡ch hÃ ng
    stage_transitions = {
        "Awareness (Nháº­n thá»©c)": "Interest (Quan tÃ¢m)",
        "Interest (Quan tÃ¢m)": "Consideration (CÃ¢n nháº¯c)",
        "Consideration (CÃ¢n nháº¯c)": "Decision (Quyáº¿t Ä‘á»‹nh)",
        "Decision (Quyáº¿t Ä‘á»‹nh)": "Action (Chuyá»ƒn khoáº£n)",
        "Action (Chuyá»ƒn khoáº£n)": "HoÃ n thÃ nh Ä‘Æ¡n hÃ ng"
    }

    next_stage = stage_transitions.get(customer_stage, "Tiáº¿p tá»¥c há»™i thoáº¡i")

    print(f"Next stage: {next_stage}")

    return next_stage

def infer_conversation_goal(customer_stage, user_message):
    """
    Sá»­ dá»¥ng LLM Ä‘á»ƒ suy luáº­n conversation_goal phÃ¹ há»£p vá»›i customer_stage vÃ  ná»™i dung tin nháº¯n.
    """
    prompt = f"""
    Dá»±a trÃªn giai Ä‘oáº¡n khÃ¡ch hÃ ng trong hÃ nh trÃ¬nh mua hÃ ng: "{customer_stage}", 
    vÃ  tin nháº¯n: "{user_message}", hÃ£y xÃ¡c Ä‘á»‹nh bÆ°á»›c há»£p lÃ½ tiáº¿p theo Ä‘á»ƒ dáº«n khÃ¡ch hÃ ng Ä‘áº¿n má»¥c tiÃªu "Chuyá»ƒn khoáº£n".
    
    Tráº£ vá» chá»‰ má»™t má»¥c tiÃªu há»™i thoáº¡i cá»¥ thá»ƒ (khÃ´ng giáº£i thÃ­ch), vÃ­ dá»¥: "Giá»›i thiá»‡u sáº£n pháº©m", "Thuyáº¿t phá»¥c khÃ¡ch hÃ ng", "HÆ°á»›ng dáº«n thanh toÃ¡n".
    """

    response = llm.invoke(prompt).content  # Gá»i LLM Ä‘á»ƒ phÃ¢n tÃ­ch
    return response.strip()


def determine_conversation_goal(customer_info, user_message, customer_stage):
    """
    XÃ¡c Ä‘á»‹nh má»¥c tiÃªu há»™i thoáº¡i dá»±a trÃªn thÃ´ng tin khÃ¡ch hÃ ng, ná»™i dung tin nháº¯n vÃ  giai Ä‘oáº¡n khÃ¡ch hÃ ng.
    """
    print("user_message in the determine_conversation_goal:", user_message)
    print("customer_info in the determine_conversation_goal:", customer_info)
    print("customer_stage in the determine_conversation_goal:", customer_stage)

    # Náº¿u thÃ´ng tin khÃ¡ch cÃ²n thiáº¿u, cáº§n tiáº¿p tá»¥c há»i Ä‘á»ƒ hoÃ n chá»‰nh
    if "missing_fields" in customer_info and len(customer_info["missing_fields"]) > 0:
        return "Khá»Ÿi táº¡o há»™i thoáº¡i chung"

    # XÃ¡c Ä‘á»‹nh má»¥c tiÃªu tiáº¿p theo báº±ng cÃ¡ch suy luáº­n tá»« company_goal
    conversation_goal = infer_conversation_goal(customer_stage, user_message)

    return conversation_goal


def create_best_map(conversation_goal, customer_info, company_goal, product_info):
    """
    Sá»­ dá»¥ng LLM Ä‘á»ƒ suy luáº­n Best_map phÃ¹ há»£p dá»±a trÃªn conversation_goal, customer_info vÃ  company_goal.
    """
    prompt = f"""
    ğŸ›’ KhÃ¡ch hÃ ng Ä‘ang á»Ÿ giai Ä‘oáº¡n: "{customer_info.get('customer_stage', 'Unknown')}"
    ğŸ¯ Má»¥c tiÃªu há»™i thoáº¡i: "{conversation_goal}"
    ğŸ† Má»¥c tiÃªu cuá»‘i cÃ¹ng cá»§a cÃ´ng ty: "{company_goal}"
    ğŸ‘¤ ThÃ´ng tin khÃ¡ch hÃ ng: {customer_info}
    ğŸ“¦ ThÃ´ng tin sáº£n pháº©m cÃ´ng ty: {product_info}

    âœ… HÃ£y táº¡o má»™t hÆ°á»›ng dáº«n pháº£n há»“i tá»‘t nháº¥t (Best_map) giÃºp nhÃ¢n viÃªn bÃ¡n hÃ ng nÃ³i chuyá»‡n há»£p lÃ½ vÃ  hÆ°á»›ng khÃ¡ch hÃ ng Ä‘áº¿n {company_goal}.
    âœ… Äiá»u chá»‰nh pháº£n há»“i dá»±a trÃªn cáº£m xÃºc vÃ  giai Ä‘oáº¡n cá»§a khÃ¡ch hÃ ng:
    - Náº¿u chÆ°a biáº¿t tÃªn khÃ¡ch hÃ ng, hÃ£y há»i tÃªn khÃ¡ch hÃ ng trÆ°á»›c.
    - Náº¿u khÃ¡ch hÃ ng cÃ²n phÃ¢n vÃ¢n, hÃ£y nháº¥n máº¡nh lá»£i Ã­ch cá»§a sáº£n pháº©m.
    - Náº¿u khÃ¡ch hÃ ng cÃ³ há»©ng thÃº, hÃ£y gá»£i má»Ÿ má»™t lÃ½ do máº¡nh máº½ Ä‘á»ƒ hÃ nh Ä‘á»™ng ngay.
    - Náº¿u khÃ¡ch hÃ ng cÃ³ lo ngáº¡i, hÃ£y tráº¥n an vÃ  cung cáº¥p thÃ´ng tin há»— trá»£.

    ğŸ¤ Náº¿u biáº¿t tÃªn khÃ¡ch hÃ ng, hÃ£y xÆ°ng hÃ´ thÃ¢n thiá»‡n.
    ğŸ“¢ Tráº£ vá» má»™t Ä‘oáº¡n vÄƒn ngáº¯n, khÃ´ng quÃ¡ 3 cÃ¢u, vá»›i phong cÃ¡ch giao tiáº¿p thÆ°á»ng thá»©c (casual).
    """
    response = llm.invoke(prompt).content  # Gá»i OpenAI hoáº·c mÃ´ hÃ¬nh AI khÃ¡c
    return response.strip()


def search_sales_skills(query_text, max_skills=3):
    """ 
    Truy váº¥n ká»¹ nÄƒng tá»« Pinecone vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n. 
    """
    embedding_model = OpenAIEmbeddings(model="text-embedding-3-large", dimensions=1536)
    query_embedding = embedding_model.embed_query(query_text)

    index = pc.Index(index_name)
    response = index.query(
        vector=query_embedding,
        top_k=max_skills,
        include_metadata=True  
    )

    skills = []
    if response and "matches" in response:
        for match in response["matches"]:
            skill_text = match.get("metadata", {}).get("content")
            if skill_text:
                skills.append(skill_text)

    return skills if skills else ["KhÃ´ng tÃ¬m tháº¥y ká»¹ nÄƒng phÃ¹ há»£p."]


def search_sales_skills_ok1(query_text, max_skills=3):
    """Truy váº¥n ká»¹ nÄƒng bÃ¡n hÃ ng tá»« Pinecone dá»±a trÃªn Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng vá»›i input cá»§a ngÆ°á»i dÃ¹ng."""
    
    # ğŸ”¹ Náº¿u lÃ  cÃ¢u chÃ o, tÃ¬m ká»¹ nÄƒng má»Ÿ Ä‘áº§u
    greeting_keywords = ["chÃ o", "hello", "hi", "xin chÃ o"]
    if any(word in query_text.lower() for word in greeting_keywords):
        query_text = "Ká»¹ nÄƒng má»Ÿ lá»i"
    
    embedding_model = OpenAIEmbeddings(model="text-embedding-3-large", dimensions=1536)
    query_embedding = embedding_model.embed_query(query_text)

    try:
        # ğŸ”¥ Gá»i Pinecone Ä‘á»ƒ tÃ¬m ká»¹ nÄƒng gáº§n nháº¥t
        index = pc.Index(index_name)
        response = index.query(
            vector=query_embedding,
            top_k=max_skills,  
            include_metadata=True  
        )

        skills = []
        if response and "matches" in response:
            for match in response["matches"]:
                score = match.get("score", 0)
                skill_text = match.get("metadata", {}).get("content").strip()
                # ğŸ”¹ Lá»c káº¿t quáº£ dá»±a trÃªn ngÆ°á»¡ng (threshold)
                if skill_text and score >= 0.6:  # Giáº£m threshold Ä‘á»ƒ khÃ´ng bá» sÃ³t ká»¹ nÄƒng
                    skills.append(skill_text)

        # ğŸ”¹ Lá»c bá» ká»¹ nÄƒng trÃ¹ng láº·p
        unique_skills = list(set(skills))

        print("ğŸ” Ká»¹ nÄƒng tÃ¬m Ä‘Æ°á»£c:", unique_skills)
        return unique_skills if unique_skills else ["KhÃ´ng tÃ¬m tháº¥y ká»¹ nÄƒng phÃ¹ há»£p."]

    except Exception as e:
        print("âš ï¸ Lá»—i truy váº¥n Pinecone:", str(e))
        return ["KhÃ´ng tÃ¬m tháº¥y ká»¹ nÄƒng phÃ¹ há»£p."]


chain = (
    RunnablePassthrough.assign(
        history=lambda _: memory.load_memory_variables({}).get("history", []),
        products=lambda x: retrieve_product(x["user_input"]),
        sales_skills=lambda x: ", ".join(search_sales_skills(x["user_input"], max_skills=3)),  # Láº¥y ká»¹ nÄƒng tá»« Pinecone
        user_style=lambda _: "lá»‹ch sá»±"
    )  
    | prompt
    | llm
)
def ami_selling(user_message, user_context=None):
    """
    HÃ m chÃ­nh xá»­ lÃ½ há»™i thoáº¡i bÃ¡n hÃ ng cá»§a Ami.
    """
    if user_context is None:
        user_context = {}

    print("user_message in the ami_selling:", user_message)

    # TrÃ­ch xuáº¥t thÃ´ng tin khÃ¡ch hÃ ng
    extracted_info = extract_customer_info(user_message)
    print("extracted_info in the ami_selling:", extracted_info)

    # Cáº­p nháº­t user_context vá»›i customer_info má»›i
    if extracted_info:
        user_context["customer_info"] = extracted_info
    else:
        user_context["customer_info"] = {"status": "missing_info"}  # Giá»¯ tráº¡ng thÃ¡i náº¿u chÆ°a cÃ³ dá»¯ liá»‡u

    print("Updated user_context:", user_context)

    company_goal = "KhÃ¡ch chuyá»ƒn khoáº£n"
    product_info = retrieve_product(user_message)

    # Gá»i handle_user_message Ä‘á»ƒ láº¥y pháº£n há»“i chÃ­nh theo Best_map
    response = handle_user_message(user_message, user_context,company_goal,product_info)

    return response

def generate_response(best_map, company_goal, customer_info):
    """
    Sinh pháº£n há»“i dá»±a trÃªn Best_map + hÆ°á»›ng khÃ¡ch hÃ ng Ä‘áº¿n company_goal.
    """
    prompt = f"""
    KhÃ¡ch hÃ ng: {customer_info}
    Best_map: "{best_map}"
    Company_goal: "{company_goal}"

    HÃ£y táº¡o má»™t pháº£n há»“i tá»± nhiÃªn, thÃ¢n thiá»‡n, dáº«n dáº¯t khÃ¡ch hÃ ng theo Best_map vÃ  hÆ°á»›ng há» Ä‘áº¿n {company_goal}.
    """

    response = llm.invoke(prompt).content  # Gá»i OpenAI hoáº·c mÃ´ hÃ¬nh AI khÃ¡c Ä‘á»ƒ sinh pháº£n há»“i
    return response.strip()