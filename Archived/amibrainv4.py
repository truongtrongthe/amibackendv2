from langchain_openai import ChatOpenAI
from Archived.knowledge import  retrieve_relevant_infov2 
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain.memory import ConversationBufferMemory
from langchain_community.chat_message_histories import ChatMessageHistory
import os
from langchain_openai import OpenAIEmbeddings
from pinecone import Pinecone, ServerlessSpec
import json
import logging
from openai import OpenAI
logging.basicConfig(level=logging.INFO)

PINECONE_API_KEY = os.getenv("PINECONE_API_KEY", "")
PINECONE_ENV = "us-east-1"  # Check Pinecone console for your region
index_name = "ami-knowledge"
llm = ChatOpenAI(model="gpt-4o", streaming=True)

prompt = PromptTemplate(
    input_variables=["history", "user_input", "products", "user_style", "sales_skills"],
    template="""
    üéØ **M·ª•c ti√™u**: Hi·ªÉu √Ω ƒë·ªãnh c·ªßa ng∆∞·ªùi d√πng v√† ph·∫£n h·ªìi m·ªôt c√°ch ph√π h·ª£p.

    1Ô∏è‚É£ **N·∫øu ng∆∞·ªùi d√πng ƒëang h·ªèi v·ªÅ s·∫£n ph·∫©m** ‚Üí D·ª±a v√†o th√¥ng tin s·∫£n ph·∫©m ƒë√£ t√¨m th·∫•y ({products}) ƒë·ªÉ t∆∞ v·∫•n ng·∫Øn g·ªçn, ƒë·ªß √Ω, c√≥ d·∫´n d·∫Øt h·ª£p l√Ω.  
    2Ô∏è‚É£ **N·∫øu ng∆∞·ªùi d√πng ƒëang h·ªèi v·ªÅ k·ªπ nƒÉng b√°n h√†ng** ‚Üí √Åp d·ª•ng k·ªπ nƒÉng ph√π h·ª£p t·ª´ ({sales_skills}) v√†o c√¢u tr·∫£ l·ªùi.  
    3Ô∏è‚É£ **N·∫øu ng∆∞·ªùi d√πng ƒëang tr√≤ chuy·ªán b√¨nh th∆∞·ªùng** ‚Üí Duy tr√¨ h·ªôi tho·∫°i m·ªôt c√°ch t·ª± nhi√™n, c√≥ th·ªÉ th√™m c√¢u h·ªèi g·ª£i m·ªü.  
    4Ô∏è‚É£ **Lu√¥n ph·∫£n h·ªìi theo phong c√°ch c·ªßa ng∆∞·ªùi d√πng tr∆∞·ªõc ƒë√¢y**: {user_style}  

    üìú **L·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán**:  
    {history}  

    üó£ **Tin nh·∫Øn t·ª´ ng∆∞·ªùi d√πng**:  
    "{user_input}"  

    ‚úçÔ∏è **Ph·∫£n h·ªìi c·ªßa AMI** (gi·ªØ phong c√°ch h·ªôi tho·∫°i ph√π h·ª£p):  
    """
)

#  chat_history = ChatMessageHistory()
chat_history = ChatMessageHistory()

memory = ConversationBufferMemory(
    chat_memory=chat_history,
    memory_key="history",  # REQUIRED in newer versions
    return_messages=True
)

def retrieve_product(user_input):
    """Retrieve relevant context from Pinecone and return a structured summary."""
    if user_input is None:
        return "Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p."  # Return an appropriate message if input is None

    retrieved_info = retrieve_relevant_infov2(user_input, top_k=10)

    if not retrieved_info:
        return "Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p."

    structured_summary = []
    for doc in retrieved_info:
        content = doc.get("content", "").strip()
        if content:
            structured_summary.append(content)
    return "\n\n".join(structured_summary) if structured_summary else "Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p."

pc = Pinecone(api_key=PINECONE_API_KEY)

# Check if index exists
existing_indexes = [i['name'] for i in pc.list_indexes()]
if index_name not in existing_indexes:
    pc.create_index(
        name=index_name,
        dimension=1536,  # Ensure this matches your model's output dimension
        metric="cosine",
        spec=ServerlessSpec(cloud="aws", region="us-east-1")
    )


def handle_user_message(user_message, user_context,company_goal,product_info):
    """
    X·ª≠ l√Ω tin nh·∫Øn t·ª´ ng∆∞·ªùi d√πng, x√°c ƒë·ªãnh m·ª•c ti√™u, t·∫°o Best_map v√† d·∫´n d·∫Øt h·ªôi tho·∫°i.
    """
    # B∆∞·ªõc 1: L·∫•y th√¥ng tin kh√°ch h√†ng t·ª´ user_context
    customer_info = user_context.get("customer_info", {})
    chat_history = user_context.get("chat_history", "")
    chat_history += f"\nUser: {user_message}"
    user_context["chat_history"] = chat_history  # C·∫≠p nh·∫≠t l·ªãch s·ª≠ h·ªôi tho·∫°i

    # B∆∞·ªõc 2: X√°c ƒë·ªãnh customer_stage t·ª´ l·ªãch s·ª≠ h·ªôi tho·∫°i
    customer_stage = get_customer_stage(chat_history)
    user_context["customer_stage"] = customer_stage
    print("customer_stage:", customer_stage)

    # B∆∞·ªõc 3: X√°c ƒë·ªãnh m·ª•c ti√™u h·ªôi tho·∫°i
    conversation_goal = determine_conversation_goal(customer_info, user_message, customer_stage)
    print("conversation_goal in handle_user_message:", conversation_goal)

    # B∆∞·ªõc 3: C·∫≠p nh·∫≠t customer_info v·ªõi customer_stage
    customer_info["customer_stage"] = customer_stage
    # B∆∞·ªõc 4: T·∫°o Best_map
    best_map = create_best_map(conversation_goal, customer_info,company_goal,product_info)
    print("best_map in handle_user_message:", best_map)

    response = generate_response(best_map, company_goal, customer_info)
    return response


def get_customer_stage(chat_history, company_goal="kh√°ch chuy·ªÉn kho·∫£n"):
    """
    D√πng LLM ƒë·ªÉ x√°c ƒë·ªãnh giai ƒëo·∫°n c·ªßa kh√°ch h√†ng d·ª±a tr√™n l·ªãch s·ª≠ h·ªôi tho·∫°i.
    """
    prompt = f"""
    B·∫°n l√† m·ªôt AI t∆∞ v·∫•n b√°n h√†ng. D∆∞·ªõi ƒë√¢y l√† l·ªãch s·ª≠ h·ªôi tho·∫°i gi·ªØa nh√¢n vi√™n v√† kh√°ch h√†ng:
    {chat_history}
    
    C√¥ng ty c√≥ m·ª•c ti√™u cu·ªëi c√πng l√† '{company_goal}'.
    D·ª±a v√†o l·ªãch s·ª≠ h·ªôi tho·∫°i, h√£y x√°c ƒë·ªãnh kh√°ch h√†ng ƒëang ·ªü giai ƒëo·∫°n n√†o trong h√†nh tr√¨nh n√†y:
    - Awareness (Nh·∫≠n th·ª©c)
    - Interest (Quan t√¢m)
    - Consideration (C√¢n nh·∫Øc)
    - Decision (Quy·∫øt ƒë·ªãnh)
    - Action (Chuy·ªÉn kho·∫£n)
    
    Ch·ªâ tr·∫£ v·ªÅ m·ªôt trong c√°c giai ƒëo·∫°n tr√™n m√† kh√¥ng c√≥ b·∫•t k·ª≥ gi·∫£i th√≠ch n√†o.
    """

    response= llm.invoke(prompt).content
    return response.strip()


def get_customer_emotion(chat_history):
   
    prompt = f"""
    B·∫°n l√† m·ªôt chuy√™n gia t√¢m l√Ω tinh t·∫ø. H√£y ph√°t hi·ªán c·∫£m x√∫c hi·ªán t·∫°i c·ªßa kh√°ch h√†ng d·ª±a tr√™n l·ªãch s·ª≠ h·ªôi tho·∫°i:
    {chat_history}
    Ch·ªâ tr·∫£ v·ªÅ tr·∫°ng th√°i c·∫£m x√∫c m√† kh√¥ng gi·∫£i th√≠ch th√™m
    """
    response= llm.invoke(prompt).content
    return response.strip()

def extract_customer_info(chat_history):
    print("chat_history in the extract_customer_info:", chat_history)
    """
    D√πng LLM ƒë·ªÉ ph√¢n t√≠ch l·ªãch s·ª≠ h·ªôi tho·∫°i v√† tr√≠ch xu·∫•t th√¥ng tin kh√°ch h√†ng.
    """
    prompt = f"""
    D∆∞·ªõi ƒë√¢y l√† l·ªãch s·ª≠ h·ªôi tho·∫°i gi·ªØa AI v√† kh√°ch h√†ng:
    {chat_history}

    D·ª±a v√†o n·ªôi dung n√†y, h√£y tr√≠ch xu·∫•t c√°c th√¥ng tin sau (n·∫øu c√≥):
    - T√™n kh√°ch h√†ng (name)
    - Tu·ªïi (age)
    - Gi·ªõi t√≠nh (gender)
    - Ngh·ªÅ nghi·ªáp (occupation)
    - S·ªü th√≠ch (interests)
    - L·ªãch s·ª≠ mua h√†ng (purchase_history)

    Tr·∫£ v·ªÅ m·ªôt JSON v·ªõi c√°c tr∆∞·ªùng t∆∞∆°ng ·ª©ng.
    N·∫øu kh√¥ng c√≥ th√¥ng tin, ƒë·ªÉ tr·ªëng.
    """

    response = llm.invoke(prompt).content  # G·ªçi LLM ƒë·ªÉ ph√¢n t√≠ch

    try:
        # L√†m s·∫°ch chu·ªói JSON n·∫øu c√≥ d·∫•u ```json ho·∫∑c ``` th·ª´a
        json_start = response.find("{")
        json_end = response.rfind("}") + 1
        clean_json = response[json_start:json_end]

        # Parse JSON
        extracted_info = json.loads(clean_json)
        print("Extracted customer info:", extracted_info)

        return extracted_info
    except json.JSONDecodeError as e:
        print("JSON decoding error:", e)
        return {}

def update_customer_info(current_info, new_info):
    """
    C·∫≠p nh·∫≠t th√¥ng tin kh√°ch h√†ng v·ªõi d·ªØ li·ªáu m·ªõi.
    """
    for key, value in new_info.items():
        if value:  # Ch·ªâ c·∫≠p nh·∫≠t n·∫øu c√≥ th√¥ng tin m·ªõi
            current_info[key] = value
    
    # Ki·ªÉm tra n·∫øu v·∫´n c√≤n missing fields
    missing_fields = [key for key, value in current_info.items() if not value]
    if missing_fields:
        current_info["status"] = "missing_info"
        current_info["missing_fields"] = missing_fields
    else:
        current_info["status"] = "completed"

    return current_info

def chat_pipeline(user_message, chat_history, customer_info, llm):
    """
    X·ª≠ l√Ω h·ªôi tho·∫°i theo pipeline:
    1. Tr√≠ch xu·∫•t th√¥ng tin kh√°ch h√†ng
    2. C·∫≠p nh·∫≠t customer_info
    3. Ti·∫øp t·ª•c h·ªôi tho·∫°i d·ª±a tr√™n t√¨nh tr·∫°ng customer_info
    """
    # 1. Tr√≠ch xu·∫•t th√¥ng tin t·ª´ l·ªãch s·ª≠ chat
    new_info = extract_customer_info(chat_history, llm)
    print("new_info:", new_info)

    # 2. C·∫≠p nh·∫≠t th√¥ng tin kh√°ch h√†ng
    customer_info = update_customer_info(customer_info, new_info)
    print("customer_info:", customer_info)
    # 3. Ki·ªÉm tra xem ƒë√£ ƒë·ªß th√¥ng tin ch∆∞a
    if customer_info["status"] == "missing_info":
        missing = customer_info["missing_fields"]
        next_question = ask_for_missing_info(missing)
        return next_question, customer_info
    
    # 4. N·∫øu ƒë√£ ƒë·ªß th√¥ng tin, ti·∫øp t·ª•c h·ªôi tho·∫°i
    response = continue_conversation(user_message, customer_info, llm)
    return response, customer_info
def ask_for_missing_info(missing_fields):
    """
    Sinh c√¢u h·ªèi ƒë·ªÉ ti·∫øp t·ª•c ho√†n thi·ªán th√¥ng tin kh√°ch h√†ng.
    """
    questions = {
        "name": "B·∫°n c√≥ th·ªÉ cho t√¥i bi·∫øt t√™n c·ªßa b·∫°n kh√¥ng?",
        "age": "B·∫°n bao nhi√™u tu·ªïi?",
        "gender": "B·∫°n l√† nam hay n·ªØ?",
        "occupation": "B·∫°n ƒëang l√†m ngh·ªÅ g√¨?",
        "interests": "B·∫°n quan t√¢m ƒë·∫øn lƒ©nh v·ª±c n√†o?",
        "purchase_history": "B·∫°n ƒë√£ t·ª´ng mua s·∫£n ph·∫©m n√†o t∆∞∆°ng t·ª± ch∆∞a?"
    }
    for field in missing_fields:
        if field in questions:
            return questions[field]  # H·ªèi l·∫ßn l∆∞·ª£t t·ª´ng c√¢u
    return "H√£y cho t√¥i bi·∫øt th√™m v·ªÅ b·∫°n!"  # N·∫øu kh√¥ng c√≥ c√¢u h·ªèi c·ª• th·ªÉ
def continue_conversation(user_message, customer_info, llm):
    """
    Ti·∫øp t·ª•c h·ªôi tho·∫°i d·ª±a tr√™n th√¥ng tin kh√°ch h√†ng v√† m·ª•c ti√™u h·ªôi tho·∫°i.
    """
    conversation_goal = determine_conversation_goal(user_message, customer_info)
    
    best_map = create_best_map(conversation_goal, customer_info)
    
    response = llm.generate(f"D·ª±a v√†o m·ª•c ti√™u '{conversation_goal}', h√£y ph·∫£n h·ªìi: {user_message}")
    
    return response


def determine_conversation_goal_hardcoded(customer_info, user_message, customer_stage):
    """
    X√°c ƒë·ªãnh m·ª•c ti√™u h·ªôi tho·∫°i d·ª±a tr√™n ƒëi·ªÉm hi·ªán t·∫°i (customer_stage) v√† m·ª•c ti√™u ti·∫øp theo.
    """
    print("user_message in the determine_conversation_goal:", user_message)
    print("customer_info in the determine_conversation_goal:", customer_info)
    print("customer_stage in the determine_conversation_goal:", customer_stage)

    if "missing_fields" in customer_info and len(customer_info["missing_fields"]) > 0:
        return "Kh·ªüi t·∫°o h·ªôi tho·∫°i chung"

    # X√°c ƒë·ªãnh "ƒëi·ªÉm B" d·ª±a tr√™n h√†nh tr√¨nh kh√°ch h√†ng
    stage_transitions = {
        "Awareness (Nh·∫≠n th·ª©c)": "Interest (Quan t√¢m)",
        "Interest (Quan t√¢m)": "Consideration (C√¢n nh·∫Øc)",
        "Consideration (C√¢n nh·∫Øc)": "Decision (Quy·∫øt ƒë·ªãnh)",
        "Decision (Quy·∫øt ƒë·ªãnh)": "Action (Chuy·ªÉn kho·∫£n)",
        "Action (Chuy·ªÉn kho·∫£n)": "Ho√†n th√†nh ƒë∆°n h√†ng"
    }

    next_stage = stage_transitions.get(customer_stage, "Ti·∫øp t·ª•c h·ªôi tho·∫°i")

    print(f"Next stage: {next_stage}")

    return next_stage

def infer_conversation_goal(customer_stage, user_message):
    """
    S·ª≠ d·ª•ng LLM ƒë·ªÉ suy lu·∫≠n conversation_goal ph√π h·ª£p v·ªõi customer_stage v√† n·ªôi dung tin nh·∫Øn.
    """
    prompt = f"""
    D·ª±a tr√™n giai ƒëo·∫°n kh√°ch h√†ng trong h√†nh tr√¨nh mua h√†ng: "{customer_stage}", 
    v√† tin nh·∫Øn: "{user_message}", h√£y x√°c ƒë·ªãnh b∆∞·ªõc h·ª£p l√Ω ti·∫øp theo ƒë·ªÉ d·∫´n kh√°ch h√†ng ƒë·∫øn m·ª•c ti√™u "Chuy·ªÉn kho·∫£n".
    
    Tr·∫£ v·ªÅ ch·ªâ m·ªôt m·ª•c ti√™u h·ªôi tho·∫°i c·ª• th·ªÉ (kh√¥ng gi·∫£i th√≠ch), v√≠ d·ª•: "Gi·ªõi thi·ªáu s·∫£n ph·∫©m", "Thuy·∫øt ph·ª•c kh√°ch h√†ng", "H∆∞·ªõng d·∫´n thanh to√°n".
    """

    response = llm.invoke(prompt).content  # G·ªçi LLM ƒë·ªÉ ph√¢n t√≠ch
    return response.strip()


def determine_conversation_goal(customer_info, user_message, customer_stage):
    """
    X√°c ƒë·ªãnh m·ª•c ti√™u h·ªôi tho·∫°i d·ª±a tr√™n th√¥ng tin kh√°ch h√†ng, n·ªôi dung tin nh·∫Øn v√† giai ƒëo·∫°n kh√°ch h√†ng.
    """
    print("user_message in the determine_conversation_goal:", user_message)
    print("customer_info in the determine_conversation_goal:", customer_info)
    print("customer_stage in the determine_conversation_goal:", customer_stage)

    # N·∫øu th√¥ng tin kh√°ch c√≤n thi·∫øu, c·∫ßn ti·∫øp t·ª•c h·ªèi ƒë·ªÉ ho√†n ch·ªânh
    if "missing_fields" in customer_info and len(customer_info["missing_fields"]) > 0:
        return "Kh·ªüi t·∫°o h·ªôi tho·∫°i chung"

    # X√°c ƒë·ªãnh m·ª•c ti√™u ti·∫øp theo b·∫±ng c√°ch suy lu·∫≠n t·ª´ company_goal
    conversation_goal = infer_conversation_goal(customer_stage, user_message)

    return conversation_goal


def create_best_map(conversation_goal, customer_info, company_goal, product_info):
    """
    S·ª≠ d·ª•ng LLM ƒë·ªÉ suy lu·∫≠n Best_map ph√π h·ª£p d·ª±a tr√™n conversation_goal, customer_info v√† company_goal.
    """
    prompt = f"""
    üõí Kh√°ch h√†ng ƒëang ·ªü giai ƒëo·∫°n: "{customer_info.get('customer_stage', 'Unknown')}"
    üéØ M·ª•c ti√™u h·ªôi tho·∫°i: "{conversation_goal}"
    üèÜ M·ª•c ti√™u cu·ªëi c√πng c·ªßa c√¥ng ty: "{company_goal}"
    üë§ Th√¥ng tin kh√°ch h√†ng: {customer_info}
    üì¶ Th√¥ng tin s·∫£n ph·∫©m c√¥ng ty: {product_info}

    ‚úÖ H√£y t·∫°o m·ªôt h∆∞·ªõng d·∫´n ph·∫£n h·ªìi t·ªët nh·∫•t (Best_map) gi√∫p nh√¢n vi√™n b√°n h√†ng n√≥i chuy·ªán h·ª£p l√Ω v√† h∆∞·ªõng kh√°ch h√†ng ƒë·∫øn {company_goal}.
    ‚úÖ ƒêi·ªÅu ch·ªânh ph·∫£n h·ªìi d·ª±a tr√™n c·∫£m x√∫c v√† giai ƒëo·∫°n c·ªßa kh√°ch h√†ng:
    - N·∫øu ch∆∞a bi·∫øt t√™n kh√°ch h√†ng, h√£y h·ªèi t√™n kh√°ch h√†ng tr∆∞·ªõc.
    - N·∫øu kh√°ch h√†ng c√≤n ph√¢n v√¢n, h√£y nh·∫•n m·∫°nh l·ª£i √≠ch c·ªßa s·∫£n ph·∫©m.
    - N·∫øu kh√°ch h√†ng c√≥ h·ª©ng th√∫, h√£y g·ª£i m·ªü m·ªôt l√Ω do m·∫°nh m·∫Ω ƒë·ªÉ h√†nh ƒë·ªông ngay.
    - N·∫øu kh√°ch h√†ng c√≥ lo ng·∫°i, h√£y tr·∫•n an v√† cung c·∫•p th√¥ng tin h·ªó tr·ª£.

    üé§ N·∫øu bi·∫øt t√™n kh√°ch h√†ng, h√£y x∆∞ng h√¥ th√¢n thi·ªán.
    üì¢ Tr·∫£ v·ªÅ m·ªôt ƒëo·∫°n vƒÉn ng·∫Øn, kh√¥ng qu√° 3 c√¢u, v·ªõi phong c√°ch giao ti·∫øp th∆∞·ªùng th·ª©c (casual).
    """
    response = llm.invoke(prompt).content  # G·ªçi OpenAI ho·∫∑c m√¥ h√¨nh AI kh√°c
    return response.strip()


def search_sales_skills(query_text, max_skills=3):
    """ 
    Truy v·∫•n k·ªπ nƒÉng t·ª´ Pinecone v·ªõi ƒë·ªô ch√≠nh x√°c cao h∆°n. 
    """
    embedding_model = OpenAIEmbeddings(model="text-embedding-3-large", dimensions=1536)
    query_embedding = embedding_model.embed_query(query_text)

    index = pc.Index(index_name)
    response = index.query(
        vector=query_embedding,
        top_k=max_skills,
        include_metadata=True  
    )

    skills = []
    if response and "matches" in response:
        for match in response["matches"]:
            skill_text = match.get("metadata", {}).get("content")
            if skill_text:
                skills.append(skill_text)

    return skills if skills else ["Kh√¥ng t√¨m th·∫•y k·ªπ nƒÉng ph√π h·ª£p."]


def search_sales_skills_ok1(query_text, max_skills=3):
    """Truy v·∫•n k·ªπ nƒÉng b√°n h√†ng t·ª´ Pinecone d·ª±a tr√™n ƒë·ªô t∆∞∆°ng ƒë·ªìng v·ªõi input c·ªßa ng∆∞·ªùi d√πng."""
    
    # üîπ N·∫øu l√† c√¢u ch√†o, t√¨m k·ªπ nƒÉng m·ªü ƒë·∫ßu
    greeting_keywords = ["ch√†o", "hello", "hi", "xin ch√†o"]
    if any(word in query_text.lower() for word in greeting_keywords):
        query_text = "K·ªπ nƒÉng m·ªü l·ªùi"
    
    embedding_model = OpenAIEmbeddings(model="text-embedding-3-large", dimensions=1536)
    query_embedding = embedding_model.embed_query(query_text)

    try:
        # üî• G·ªçi Pinecone ƒë·ªÉ t√¨m k·ªπ nƒÉng g·∫ßn nh·∫•t
        index = pc.Index(index_name)
        response = index.query(
            vector=query_embedding,
            top_k=max_skills,  
            include_metadata=True  
        )

        skills = []
        if response and "matches" in response:
            for match in response["matches"]:
                score = match.get("score", 0)
                skill_text = match.get("metadata", {}).get("content").strip()
                # üîπ L·ªçc k·∫øt qu·∫£ d·ª±a tr√™n ng∆∞·ª°ng (threshold)
                if skill_text and score >= 0.6:  # Gi·∫£m threshold ƒë·ªÉ kh√¥ng b·ªè s√≥t k·ªπ nƒÉng
                    skills.append(skill_text)

        # üîπ L·ªçc b·ªè k·ªπ nƒÉng tr√πng l·∫∑p
        unique_skills = list(set(skills))

        print("üîç K·ªπ nƒÉng t√¨m ƒë∆∞·ª£c:", unique_skills)
        return unique_skills if unique_skills else ["Kh√¥ng t√¨m th·∫•y k·ªπ nƒÉng ph√π h·ª£p."]

    except Exception as e:
        print("‚ö†Ô∏è L·ªói truy v·∫•n Pinecone:", str(e))
        return ["Kh√¥ng t√¨m th·∫•y k·ªπ nƒÉng ph√π h·ª£p."]


chain = (
    RunnablePassthrough.assign(
        history=lambda _: memory.load_memory_variables({}).get("history", []),
        products=lambda x: retrieve_product(x["user_input"]),
        sales_skills=lambda x: ", ".join(search_sales_skills(x["user_input"], max_skills=3)),  # L·∫•y k·ªπ nƒÉng t·ª´ Pinecone
        user_style=lambda _: "l·ªãch s·ª±"
    )  
    | prompt
    | llm
)
def ami_selling(user_message, user_context=None):
    """
    H√†m ch√≠nh x·ª≠ l√Ω h·ªôi tho·∫°i b√°n h√†ng c·ªßa Ami.
    """
    if user_context is None:
        user_context = {}

    print("user_message in the ami_selling:", user_message)

    # Tr√≠ch xu·∫•t th√¥ng tin kh√°ch h√†ng
    extracted_info = extract_customer_info(user_message)
    print("extracted_info in the ami_selling:", extracted_info)

    # C·∫≠p nh·∫≠t user_context v·ªõi customer_info m·ªõi
    if extracted_info:
        user_context["customer_info"] = extracted_info
    else:
        user_context["customer_info"] = {"status": "missing_info"}  # Gi·ªØ tr·∫°ng th√°i n·∫øu ch∆∞a c√≥ d·ªØ li·ªáu

    print("Updated user_context:", user_context)

    company_goal = "Kh√°ch chuy·ªÉn kho·∫£n"
    product_info = retrieve_product(user_message)

    # G·ªçi handle_user_message ƒë·ªÉ l·∫•y ph·∫£n h·ªìi ch√≠nh theo Best_map
    response = handle_user_message(user_message, user_context,company_goal,product_info)

    return response

def generate_response(best_map, company_goal, customer_info):
    """
    Sinh ph·∫£n h·ªìi d·ª±a tr√™n Best_map + h∆∞·ªõng kh√°ch h√†ng ƒë·∫øn company_goal.
    """
    prompt = f"""
    Kh√°ch h√†ng: {customer_info}
    Best_map: "{best_map}"
    Company_goal: "{company_goal}"

    H√£y t·∫°o m·ªôt ph·∫£n h·ªìi t·ª± nhi√™n, th√¢n thi·ªán, d·∫´n d·∫Øt kh√°ch h√†ng theo Best_map v√† h∆∞·ªõng h·ªç ƒë·∫øn {company_goal}.
    """

    response = llm.invoke(prompt).content  # G·ªçi OpenAI ho·∫∑c m√¥ h√¨nh AI kh√°c ƒë·ªÉ sinh ph·∫£n h·ªìi
    return response.strip()