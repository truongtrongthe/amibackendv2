from langchain_openai import ChatOpenAI
from Archived.knowledge import  retrieve_relevant_infov2 
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain.memory import ConversationBufferMemory
from langchain_community.chat_message_histories import ChatMessageHistory
import os
from langchain_openai import OpenAIEmbeddings
from pinecone import Pinecone, ServerlessSpec

# Initialize LLM for conversation

PINECONE_API_KEY = os.getenv("PINECONE_API_KEY", "")
PINECONE_ENV = "us-east-1"  # Check Pinecone console for your region
index_name = "ami-knowledge"
llm = ChatOpenAI(model="gpt-4o", streaming=True)

prompt_old = PromptTemplate(
    input_variables=["history", "user_input", "products", "user_style", "sales_skills"],
    template="""
    Dá»±a vÃ o cÃ¡c thÃ´ng tin trÆ°á»›c Ä‘Ã¢y cá»§a ngÆ°á»i dÃ¹ng, hÃ£y Ä‘áº£m báº£o cÃ¢u tráº£ lá»i phÃ¹ há»£p vá»›i phong cÃ¡ch cá»§a há».
    Lá»‹ch sá»­ cuá»™c trÃ² chuyá»‡n:
    {history}

    Sáº£n pháº©m liÃªn quan:
    {products}

    ğŸ“Œ Ká»¹ nÄƒng bÃ¡n hÃ ng cáº§n Ã¡p dá»¥ng:
    {sales_skills}

    ğŸ“¢ **HÆ°á»›ng dáº«n cho AMI:**
    1. Ãp dá»¥ng cÃ¡c ká»¹ nÄƒng vÃ o pháº£n há»“i Ä‘á»ƒ giÃºp cuá»™c trÃ² chuyá»‡n tá»± nhiÃªn hÆ¡n.
    2. Náº¿u cÃ³ ká»¹ nÄƒng "Láº¯ng nghe chá»§ Ä‘á»™ng" â†’ HÃ£y paraphrase láº¡i Ã½ cá»§a khÃ¡ch hÃ ng trÆ°á»›c khi tÆ° váº¥n.
    3. Náº¿u cÃ³ ká»¹ nÄƒng "Ká»ƒ chuyá»‡n" â†’ HÃ£y thÃªm má»™t cÃ¢u chuyá»‡n ngáº¯n Ä‘á»ƒ minh há»a sáº£n pháº©m.
    4. Náº¿u cÃ³ ká»¹ nÄƒng "Giáº£i quyáº¿t pháº£n Ä‘á»‘i" â†’ HÃ£y xá»­ lÃ½ lo ngáº¡i cá»§a khÃ¡ch hÃ ng trÆ°á»›c khi tÆ° váº¥n.

    NgÆ°á»i dÃ¹ng: {user_input}
    ğŸ¯ **AMI (giá»¯ nguyÃªn phong cÃ¡ch cá»§a ngÆ°á»i dÃ¹ng + Ã¡p dá»¥ng ká»¹ nÄƒng bÃ¡n hÃ ng):**
    """
)
prompt = PromptTemplate(
    input_variables=["history", "user_input", "products", "user_style", "sales_skills"],
    template="""
    ğŸ¯ **Má»¥c tiÃªu**: Hiá»ƒu Ã½ Ä‘á»‹nh cá»§a ngÆ°á»i dÃ¹ng vÃ  pháº£n há»“i má»™t cÃ¡ch phÃ¹ há»£p.

    1ï¸âƒ£ **Náº¿u ngÆ°á»i dÃ¹ng Ä‘ang há»i vá» sáº£n pháº©m** â†’ Dá»±a vÃ o thÃ´ng tin sáº£n pháº©m Ä‘Ã£ tÃ¬m tháº¥y ({products}) Ä‘á»ƒ tÆ° váº¥n ngáº¯n gá»n, Ä‘á»§ Ã½, cÃ³ dáº«n dáº¯t há»£p lÃ½.  
    2ï¸âƒ£ **Náº¿u ngÆ°á»i dÃ¹ng Ä‘ang há»i vá» ká»¹ nÄƒng bÃ¡n hÃ ng** â†’ Ãp dá»¥ng ká»¹ nÄƒng phÃ¹ há»£p tá»« ({sales_skills}) vÃ o cÃ¢u tráº£ lá»i.  
    3ï¸âƒ£ **Náº¿u ngÆ°á»i dÃ¹ng Ä‘ang trÃ² chuyá»‡n bÃ¬nh thÆ°á»ng** â†’ Duy trÃ¬ há»™i thoáº¡i má»™t cÃ¡ch tá»± nhiÃªn, cÃ³ thá»ƒ thÃªm cÃ¢u há»i gá»£i má»Ÿ.  
    4ï¸âƒ£ **LuÃ´n pháº£n há»“i theo phong cÃ¡ch cá»§a ngÆ°á»i dÃ¹ng trÆ°á»›c Ä‘Ã¢y**: {user_style}  

    ğŸ“œ **Lá»‹ch sá»­ cuá»™c trÃ² chuyá»‡n**:  
    {history}  

    ğŸ—£ **Tin nháº¯n tá»« ngÆ°á»i dÃ¹ng**:  
    "{user_input}"  

    âœï¸ **Pháº£n há»“i cá»§a AMI** (giá»¯ phong cÃ¡ch há»™i thoáº¡i phÃ¹ há»£p):  
    """
)

#  chat_history = ChatMessageHistory()
chat_history = ChatMessageHistory()

memory = ConversationBufferMemory(
    chat_memory=chat_history,
    memory_key="history",  # REQUIRED in newer versions
    return_messages=True
)

def retrieve_product(user_input):
    """Retrieve relevant context from Pinecone and return a structured summary."""
    if user_input is None:
        return "KhÃ´ng tÃ¬m tháº¥y sáº£n pháº©m phÃ¹ há»£p."  # Return an appropriate message if input is None

    retrieved_info = retrieve_relevant_infov2(user_input, top_k=10)

    if not retrieved_info:
        return "KhÃ´ng tÃ¬m tháº¥y sáº£n pháº©m phÃ¹ há»£p."

    structured_summary = []
    for doc in retrieved_info:
        content = doc.get("content", "").strip()
        if content:
            structured_summary.append(content)
    return "\n\n".join(structured_summary) if structured_summary else "KhÃ´ng tÃ¬m tháº¥y sáº£n pháº©m phÃ¹ há»£p."

pc = Pinecone(api_key=PINECONE_API_KEY)

# Check if index exists
existing_indexes = [i['name'] for i in pc.list_indexes()]
if index_name not in existing_indexes:
    pc.create_index(
        name=index_name,
        dimension=1536,  # Ensure this matches your model's output dimension
        metric="cosine",
        spec=ServerlessSpec(cloud="aws", region="us-east-1")
    )

def handle_user_message(user_message, user_context):
    """
    Xá»­ lÃ½ tin nháº¯n tá»« ngÆ°á»i dÃ¹ng, xÃ¡c Ä‘á»‹nh má»¥c tiÃªu, táº¡o Best_map vÃ  dáº«n dáº¯t há»™i thoáº¡i.
    """
    # BÆ°á»›c 1: PhÃ¢n tÃ­ch khÃ¡ch hÃ ng tá»« context
    customer_info = get_customer_info(user_context)
    print("customer_info:", customer_info)
    
    # BÆ°á»›c 2: XÃ¡c Ä‘á»‹nh má»¥c tiÃªu há»™i thoáº¡i
    conversation_goal = determine_conversation_goal(user_message, customer_info)
    print("conversation_goal:", conversation_goal)

    # BÆ°á»›c 3: Táº¡o Best_map (báº£n Ä‘á»“ dáº«n Ä‘áº¿n thÃ nh cÃ´ng)
    #best_map = create_best_map(conversation_goal)
    best_map = create_best_map(conversation_goal, user_context.get("customer_info", {}))


    # BÆ°á»›c 4: Dáº«n dáº¯t há»™i thoáº¡i theo Best_map
    response = guide_conversation(user_message, best_map, customer_info)
    #response = "test"
    return response

def get_customer_info(user_context):
    """
    PhÃ¢n tÃ­ch khÃ¡ch hÃ ng tá»« context Ä‘á»ƒ hiá»ƒu rÃµ hÆ¡n vá» ngÆ°á»i dÃ¹ng.
    """
    if user_context is None:
        return {"name": "KhÃ¡ch hÃ ng", "age": None, "gender": None, "profession": None}  

    customer_info = {
        "name": user_context.get("name"),
        "age": user_context.get("age"),
        "gender": user_context.get("gender"),
        "occupation": user_context.get("occupation"),
        "interests": user_context.get("interests"),
        "purchase_history": user_context.get("purchase_history"),
    }

    # Náº¿u thiáº¿u thÃ´ng tin quan trá»ng, yÃªu cáº§u bá»• sung
    missing_info = [key for key, value in customer_info.items() if value is None]

    if missing_info:
        return {"status": "missing_info", "missing_fields": missing_info}

    return {"status": "complete", "customer_info": customer_info}

import regex as re
def update_customer_info(user_message, customer_info):
    """
    PhÃ¢n tÃ­ch tin nháº¯n ngÆ°á»i dÃ¹ng Ä‘á»ƒ cáº­p nháº­t thÃ´ng tin khÃ¡ch hÃ ng.
    """
    updated = False

    age_match = re.search(r'(\d{1,2}) tuá»•i', user_message)
    if age_match:
        customer_info["age"] = int(age_match.group(1))
        customer_info["missing_fields"].remove("age")
        updated = True

    name_match = re.search(r'(tÃ´i tÃªn lÃ |anh lÃ |em lÃ |tÃªn tÃ´i lÃ )\s*([\w\s]+)', user_message, re.IGNORECASE)
    if name_match:
        customer_info["name"] = name_match.group(2).strip()
        customer_info["missing_fields"].remove("name")
        updated = True

    occupation_match = re.search(r'anh lÃ m (\w+)', user_message, re.IGNORECASE)
    if occupation_match:
        customer_info["occupation"] = occupation_match.group(1)
        customer_info["missing_fields"].remove("occupation")
        updated = True

    if updated:
        customer_info["status"] = "info_updated"

    return customer_info


def determine_conversation_goal(customer_info, user_message):
    """
    XÃ¡c Ä‘á»‹nh má»¥c tiÃªu há»™i thoáº¡i dá»±a trÃªn thÃ´ng tin khÃ¡ch hÃ ng vÃ  tin nháº¯n.
    """
    if "missing_fields" in customer_info and len(customer_info["missing_fields"]) > 0:
        return "Khá»Ÿi táº¡o há»™i thoáº¡i chung"
    
    if "muá»‘n cao thÃªm" in user_message:
        return "TÆ° váº¥n sáº£n pháº©m tÄƒng chiá»u cao"
    
    return "Tiáº¿p tá»¥c há»™i thoáº¡i"


def determine_conversation_goal_v1(user_message, customer_info):
    """
    XÃ¡c Ä‘á»‹nh má»¥c tiÃªu cá»§a cuá»™c trÃ² chuyá»‡n dá»±a trÃªn tin nháº¯n cá»§a user vÃ  thÃ´ng tin khÃ¡ch hÃ ng.
    """
    if not customer_info or customer_info.get("name") is None:
        return "Khá»Ÿi táº¡o há»™i thoáº¡i chung"
    
    if customer_info.get("status") == "missing_info":
        missing_fields = customer_info.get("missing_fields", [])
        if missing_fields:
            return f"HÃ£y há»i thÃªm vá» {', '.join(missing_fields)} trÆ°á»›c khi tiáº¿p tá»¥c."
        return "Khá»Ÿi táº¡o há»™i thoáº¡i chung"
    
    # Dá»±a trÃªn tin nháº¯n cá»§a user Ä‘á»ƒ xÃ¡c Ä‘á»‹nh intent
    if "tÄƒng chiá»u cao" in user_message:
        return "TÆ° váº¥n sáº£n pháº©m tÄƒng chiá»u cao"
    if "giáº£m cÃ¢n" in user_message:
        return "TÆ° váº¥n sáº£n pháº©m giáº£m cÃ¢n"
    if "muá»‘n tÃ¬m hiá»ƒu" in user_message:
        return "Cung cáº¥p thÃ´ng tin chi tiáº¿t vá» sáº£n pháº©m"
    if "giÃ¡ bao nhiÃªu" in user_message:
        return "Cung cáº¥p thÃ´ng tin giÃ¡ sáº£n pháº©m"
    if "tÆ° váº¥n giÃºp" in user_message:
        return "TÆ° váº¥n cÃ¡ nhÃ¢n hÃ³a dá»±a trÃªn nhu cáº§u khÃ¡ch hÃ ng"
    
    return "Dáº«n dáº¯t há»™i thoáº¡i Ä‘á»ƒ tÃ¬m hiá»ƒu nhu cáº§u khÃ¡ch hÃ ng"

def create_best_map(conversation_goal, customer_info):
    print("customer_info in the conversation_goal:", customer_info)
    """
    Táº¡o báº£n Ä‘á»“ há»™i thoáº¡i tá»‘t nháº¥t dá»±a trÃªn má»¥c tiÃªu há»™i thoáº¡i vÃ  thÃ´ng tin khÃ¡ch hÃ ng.
    """
    if conversation_goal == "Khá»Ÿi táº¡o há»™i thoáº¡i chung":
        missing = customer_info.get("missing_fields", [])
        if "name" in missing:
            return ["BÆ°á»›c 1: Há»i tÃªn khÃ¡ch hÃ ng"]
        if "age" in missing:
            return ["BÆ°á»›c 2: Há»i tuá»•i khÃ¡ch hÃ ng"]
        if "occupation" in missing:
            return ["BÆ°á»›c 3: Há»i nghá» nghiá»‡p khÃ¡ch hÃ ng"]
        return ["BÆ°á»›c 4: HoÃ n thÃ nh há»“ sÆ¡ khÃ¡ch hÃ ng"]

    if conversation_goal == "TÆ° váº¥n sáº£n pháº©m tÄƒng chiá»u cao":
        return [
            "BÆ°á»›c 1: XÃ¡c nháº­n mong muá»‘n tÄƒng chiá»u cao",
            "BÆ°á»›c 2: Giá»›i thiá»‡u sáº£n pháº©m phÃ¹ há»£p",
            "BÆ°á»›c 3: Giáº£i Ä‘Ã¡p tháº¯c máº¯c"
        ]
    
    return ["BÆ°á»›c 1: Tiáº¿p tá»¥c há»™i thoáº¡i"]


def create_best_map_v1(conversation_goal):
    """
    Dá»±a vÃ o má»¥c tiÃªu há»™i thoáº¡i, tÃ¬m cÃ¡c ká»¹ nÄƒng phÃ¹ há»£p trong Pinecone Ä‘á»ƒ xÃ¢y dá»±ng Best_map.
    """
    relevant_skills = search_sales_skills(conversation_goal)
    print("DEBUG: relevant_skills =", relevant_skills)
    
    best_map = []
    
    if conversation_goal == "Khá»Ÿi táº¡o há»™i thoáº¡i chung":
        best_map.append("BÆ°á»›c 1: ChÃ o há»i vÃ  tÃ¬m hiá»ƒu nhu cáº§u khÃ¡ch hÃ ng")
    
    if "khai thÃ¡c thÃ´ng tin cÃ¡ nhÃ¢n" in relevant_skills:
        best_map.append("BÆ°á»›c 1: Khai thÃ¡c thÃ´ng tin khÃ¡ch hÃ ng (TÃªn, tuá»•i, nghá» nghiá»‡p)")
    if "khÆ¡i gá»£i Ä‘á»™ng lá»±c" in relevant_skills:
        best_map.append("BÆ°á»›c 2: KhÆ¡i gá»£i Ä‘á»™ng lá»±c (Lá»£i Ã­ch sáº£n pháº©m, tÃ¡c Ä‘á»™ng thá»±c táº¿)")
    if "Ä‘Æ°a vÃ­ dá»¥ thuyáº¿t phá»¥c" in relevant_skills:
        best_map.append("BÆ°á»›c 3: ÄÆ°a vÃ­ dá»¥ thá»±c táº¿ (CÃ¢u chuyá»‡n thÃ nh cÃ´ng cá»§a khÃ¡ch hÃ ng khÃ¡c)")
    if "Ä‘á» xuáº¥t giáº£i phÃ¡p" in relevant_skills:
        best_map.append("BÆ°á»›c 4: Äá» xuáº¥t sáº£n pháº©m phÃ¹ há»£p vá»›i nhu cáº§u khÃ¡ch hÃ ng")
    
    # Náº¿u khÃ´ng cÃ³ bÆ°á»›c nÃ o, cung cáº¥p fallback
    if not best_map:
        best_map.append("BÆ°á»›c 1: Má»Ÿ Ä‘áº§u cuá»™c trÃ² chuyá»‡n")
    
    print("DEBUG: best_map =", best_map)
    return best_map

def guide_conversation(user_message, best_map, customer_info):
    """
    HÆ°á»›ng dáº«n há»™i thoáº¡i dá»±a trÃªn tin nháº¯n ngÆ°á»i dÃ¹ng, Best_map vÃ  thÃ´ng tin khÃ¡ch hÃ ng.
    """
    print(f"DEBUG: user_message = {user_message}")
    print(f"DEBUG: best_map = {best_map}")
    
    # Äáº£m báº£o best_map cÃ³ Ã­t nháº¥t 3 pháº§n tá»­ trÆ°á»›c khi truy cáº­p
    step_1 = best_map[0] if len(best_map) > 0 else "BÆ°á»›c 1: ChÃ o há»i vÃ  tÃ¬m hiá»ƒu nhu cáº§u khÃ¡ch hÃ ng"
    step_2 = best_map[1] if len(best_map) > 1 else None
    step_3 = best_map[2] if len(best_map) > 2 else None

    # BÆ°á»›c 1: ChÃ o há»i náº¿u chÆ°a cÃ³ thÃ´ng tin khÃ¡ch hÃ ng
    if step_1 and "chÃ o" in user_message.lower():
        return "Xin chÃ o! Báº¡n cÃ³ thá»ƒ cho mÃ¬nh biáº¿t thÃªm vá» báº¡n khÃ´ng? (TÃªn, tuá»•i, nghá» nghiá»‡p...)"

    # BÆ°á»›c 2: Khai thÃ¡c thÃ´ng tin cÃ¡ nhÃ¢n
    if step_2 and "tÃªn tÃ´i" in user_message.lower():
        return f"Cáº£m Æ¡n {user_message.split('tÃªn tÃ´i lÃ ')[-1].strip()}! Báº¡n cÃ³ thá»ƒ chia sáº» thÃªm sá»Ÿ thÃ­ch hoáº·c nhu cáº§u cá»§a mÃ¬nh khÃ´ng?"

    # BÆ°á»›c 3: Xá»­ lÃ½ nghi ngá» hoáº·c pháº£n Ä‘á»‘i
    if step_3 and "nghi ngá»" in user_message.lower():
        return "TÃ´i hiá»ƒu báº¡n cÃ³ má»™t sá»‘ tháº¯c máº¯c. ÄÃ¢y lÃ  má»™t sá»‘ pháº£n há»“i tá»« khÃ¡ch hÃ ng Ä‘Ã£ tá»«ng sá»­ dá»¥ng sáº£n pháº©m cá»§a chÃºng tÃ´i..."

    # Náº¿u khÃ´ng khá»›p báº¥t ká»³ bÆ°á»›c nÃ o, dáº«n dáº¯t láº¡i
    return "Báº¡n cÃ³ thá»ƒ nÃ³i rÃµ hÆ¡n vá» nhu cáº§u hoáº·c cÃ¢u há»i cá»§a báº¡n khÃ´ng?"


def search_sales_skills(query_text, max_skills=3):
    """ 
    Truy váº¥n ká»¹ nÄƒng tá»« Pinecone vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n. 
    """
    embedding_model = OpenAIEmbeddings(model="text-embedding-3-large", dimensions=1536)
    query_embedding = embedding_model.embed_query(query_text)

    index = pc.Index(index_name)
    response = index.query(
        vector=query_embedding,
        top_k=max_skills,
        include_metadata=True  
    )

    skills = []
    if response and "matches" in response:
        for match in response["matches"]:
            skill_text = match.get("metadata", {}).get("content")
            if skill_text:
                skills.append(skill_text)

    return skills if skills else ["KhÃ´ng tÃ¬m tháº¥y ká»¹ nÄƒng phÃ¹ há»£p."]


def search_sales_skills_basic(query_text, max_skills=3):
    """Truy váº¥n ká»¹ nÄƒng bÃ¡n hÃ ng tá»« Pinecone dá»±a trÃªn Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng vá»›i input cá»§a ngÆ°á»i dÃ¹ng."""
    embedding_model = OpenAIEmbeddings(model="text-embedding-3-large", dimensions=1536)
    query_embedding = embedding_model.embed_query(query_text)

    # TÃ¬m kiáº¿m trong Pinecone
    index = pc.Index(index_name)
    response = index.query(
        vector=query_embedding,
        top_k=max_skills,  
        include_metadata=True  
    )

    skills = []
    if response and "matches" in response:
        for match in response["matches"]:
            skill_text = match.get("metadata", {}).get("content")
            score = match.get("score", 0.0)  # Láº¥y Ä‘iá»ƒm tÆ°Æ¡ng Ä‘á»“ng

            # ğŸš€ Chá»‰ loáº¡i bá» náº¿u score < 0.0 (cÃ²n láº¡i váº«n láº¥y)
            if skill_text and score >= 0.0:  
                skills.append(skill_text)

    print("ğŸ” Ká»¹ nÄƒng tÃ¬m Ä‘Æ°á»£c:", skills)
    return skills if skills else ["KhÃ´ng tÃ¬m tháº¥y ká»¹ nÄƒng phÃ¹ há»£p."]


def search_sales_skills_ok1(query_text, max_skills=3):
    """Truy váº¥n ká»¹ nÄƒng bÃ¡n hÃ ng tá»« Pinecone dá»±a trÃªn Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng vá»›i input cá»§a ngÆ°á»i dÃ¹ng."""
    
    # ğŸ”¹ Náº¿u lÃ  cÃ¢u chÃ o, tÃ¬m ká»¹ nÄƒng má»Ÿ Ä‘áº§u
    greeting_keywords = ["chÃ o", "hello", "hi", "xin chÃ o"]
    if any(word in query_text.lower() for word in greeting_keywords):
        query_text = "Ká»¹ nÄƒng má»Ÿ lá»i"
    
    embedding_model = OpenAIEmbeddings(model="text-embedding-3-large", dimensions=1536)
    query_embedding = embedding_model.embed_query(query_text)

    try:
        # ğŸ”¥ Gá»i Pinecone Ä‘á»ƒ tÃ¬m ká»¹ nÄƒng gáº§n nháº¥t
        index = pc.Index(index_name)
        response = index.query(
            vector=query_embedding,
            top_k=max_skills,  
            include_metadata=True  
        )

        skills = []
        if response and "matches" in response:
            for match in response["matches"]:
                score = match.get("score", 0)
                skill_text = match.get("metadata", {}).get("content").strip()
                # ğŸ”¹ Lá»c káº¿t quáº£ dá»±a trÃªn ngÆ°á»¡ng (threshold)
                if skill_text and score >= 0.6:  # Giáº£m threshold Ä‘á»ƒ khÃ´ng bá» sÃ³t ká»¹ nÄƒng
                    skills.append(skill_text)

        # ğŸ”¹ Lá»c bá» ká»¹ nÄƒng trÃ¹ng láº·p
        unique_skills = list(set(skills))

        print("ğŸ” Ká»¹ nÄƒng tÃ¬m Ä‘Æ°á»£c:", unique_skills)
        return unique_skills if unique_skills else ["KhÃ´ng tÃ¬m tháº¥y ká»¹ nÄƒng phÃ¹ há»£p."]

    except Exception as e:
        print("âš ï¸ Lá»—i truy váº¥n Pinecone:", str(e))
        return ["KhÃ´ng tÃ¬m tháº¥y ká»¹ nÄƒng phÃ¹ há»£p."]


chain = (
    RunnablePassthrough.assign(
        history=lambda _: memory.load_memory_variables({}).get("history", []),
        products=lambda x: retrieve_product(x["user_input"]),
        sales_skills=lambda x: ", ".join(search_sales_skills(x["user_input"], max_skills=3)),  # Láº¥y ká»¹ nÄƒng tá»« Pinecone
        user_style=lambda _: "lá»‹ch sá»±"
    )  
    | prompt
    | llm
)

def ami_selling_basic(query):
    print("query:", query)
    input_data = {"user_input": query}
    # Láº¥y ká»¹ nÄƒng phÃ¹ há»£p
    relevant_skills = search_sales_skills(query)

    # Náº¿u cÃ³ ká»¹ nÄƒng, sá»­a query Ä‘á»ƒ nháº¯c AMI
    if relevant_skills and relevant_skills[0] != "KhÃ´ng tÃ¬m tháº¥y ká»¹ nÄƒng phÃ¹ há»£p.":
        input_data["user_input"] += f"\n\nğŸ“Œ HÃ£y Ã¡p dá»¥ng ká»¹ nÄƒng nÃ y vÃ o cÃ¢u tráº£ lá»i: {', '.join(relevant_skills)}"

    last_response =""
    response_stream = chain.stream(input_data)
    yield from (chunk.content if hasattr(chunk, 'content') else chunk for chunk in response_stream)  # Handle both cases
    #yield "Hey hello I'm Ami" # âœ… CÃ¡ch khÃ¡c
    memory.save_context({"input": query}, {"output": last_response.strip()})
def ami_selling(user_message, user_context=None):
    """
    HÃ m chÃ­nh xá»­ lÃ½ há»™i thoáº¡i bÃ¡n hÃ ng cá»§a Ami.
    """
    if user_context is None:
        user_context = {}
    # Gá»i handle_user_message Ä‘á»ƒ láº¥y pháº£n há»“i chÃ­nh theo Best_map
    response = handle_user_message(user_message, user_context)

    # Bá»• sung yáº¿u tá»‘ bÃ¡n hÃ ng vÃ o pháº£n há»“i
    sales_prompt = "ÄÃ¢y lÃ  sáº£n pháº©m em Ä‘á» xuáº¥t cho anh/chá»‹: ..."
    if "BÆ°á»›c 4" in response:
        response += f"\n{sales_prompt}"

    return response
