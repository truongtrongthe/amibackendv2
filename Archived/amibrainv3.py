from langchain_openai import ChatOpenAI
from Archived.knowledge import  retrieve_relevant_infov2 
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain.memory import ConversationBufferMemory
from langchain_community.chat_message_histories import ChatMessageHistory
import os
from langchain_openai import OpenAIEmbeddings
from pinecone import Pinecone, ServerlessSpec

# Initialize LLM for conversation

PINECONE_API_KEY = os.getenv("PINECONE_API_KEY", "")
PINECONE_ENV = "us-east-1"  # Check Pinecone console for your region
index_name = "ami-knowledge"
llm = ChatOpenAI(model="gpt-4o", streaming=True)

prompt_old = PromptTemplate(
    input_variables=["history", "user_input", "products", "user_style", "sales_skills"],
    template="""
    D·ª±a v√†o c√°c th√¥ng tin tr∆∞·ªõc ƒë√¢y c·ªßa ng∆∞·ªùi d√πng, h√£y ƒë·∫£m b·∫£o c√¢u tr·∫£ l·ªùi ph√π h·ª£p v·ªõi phong c√°ch c·ªßa h·ªç.
    L·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán:
    {history}

    S·∫£n ph·∫©m li√™n quan:
    {products}

    üìå K·ªπ nƒÉng b√°n h√†ng c·∫ßn √°p d·ª•ng:
    {sales_skills}

    üì¢ **H∆∞·ªõng d·∫´n cho AMI:**
    1. √Åp d·ª•ng c√°c k·ªπ nƒÉng v√†o ph·∫£n h·ªìi ƒë·ªÉ gi√∫p cu·ªôc tr√≤ chuy·ªán t·ª± nhi√™n h∆°n.
    2. N·∫øu c√≥ k·ªπ nƒÉng "L·∫Øng nghe ch·ªß ƒë·ªông" ‚Üí H√£y paraphrase l·∫°i √Ω c·ªßa kh√°ch h√†ng tr∆∞·ªõc khi t∆∞ v·∫•n.
    3. N·∫øu c√≥ k·ªπ nƒÉng "K·ªÉ chuy·ªán" ‚Üí H√£y th√™m m·ªôt c√¢u chuy·ªán ng·∫Øn ƒë·ªÉ minh h·ªça s·∫£n ph·∫©m.
    4. N·∫øu c√≥ k·ªπ nƒÉng "Gi·∫£i quy·∫øt ph·∫£n ƒë·ªëi" ‚Üí H√£y x·ª≠ l√Ω lo ng·∫°i c·ªßa kh√°ch h√†ng tr∆∞·ªõc khi t∆∞ v·∫•n.

    Ng∆∞·ªùi d√πng: {user_input}
    üéØ **AMI (gi·ªØ nguy√™n phong c√°ch c·ªßa ng∆∞·ªùi d√πng + √°p d·ª•ng k·ªπ nƒÉng b√°n h√†ng):**
    """
)
prompt = PromptTemplate(
    input_variables=["history", "user_input", "products", "user_style", "sales_skills"],
    template="""
    üéØ **M·ª•c ti√™u**: Hi·ªÉu √Ω ƒë·ªãnh c·ªßa ng∆∞·ªùi d√πng v√† ph·∫£n h·ªìi m·ªôt c√°ch ph√π h·ª£p.

    1Ô∏è‚É£ **N·∫øu ng∆∞·ªùi d√πng ƒëang h·ªèi v·ªÅ s·∫£n ph·∫©m** ‚Üí D·ª±a v√†o th√¥ng tin s·∫£n ph·∫©m ƒë√£ t√¨m th·∫•y ({products}) ƒë·ªÉ t∆∞ v·∫•n ng·∫Øn g·ªçn, ƒë·ªß √Ω, c√≥ d·∫´n d·∫Øt h·ª£p l√Ω.  
    2Ô∏è‚É£ **N·∫øu ng∆∞·ªùi d√πng ƒëang h·ªèi v·ªÅ k·ªπ nƒÉng b√°n h√†ng** ‚Üí √Åp d·ª•ng k·ªπ nƒÉng ph√π h·ª£p t·ª´ ({sales_skills}) v√†o c√¢u tr·∫£ l·ªùi.  
    3Ô∏è‚É£ **N·∫øu ng∆∞·ªùi d√πng ƒëang tr√≤ chuy·ªán b√¨nh th∆∞·ªùng** ‚Üí Duy tr√¨ h·ªôi tho·∫°i m·ªôt c√°ch t·ª± nhi√™n, c√≥ th·ªÉ th√™m c√¢u h·ªèi g·ª£i m·ªü.  
    4Ô∏è‚É£ **Lu√¥n ph·∫£n h·ªìi theo phong c√°ch c·ªßa ng∆∞·ªùi d√πng tr∆∞·ªõc ƒë√¢y**: {user_style}  

    üìú **L·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán**:  
    {history}  

    üó£ **Tin nh·∫Øn t·ª´ ng∆∞·ªùi d√πng**:  
    "{user_input}"  

    ‚úçÔ∏è **Ph·∫£n h·ªìi c·ªßa AMI** (gi·ªØ phong c√°ch h·ªôi tho·∫°i ph√π h·ª£p):  
    """
)

#  chat_history = ChatMessageHistory()
chat_history = ChatMessageHistory()

memory = ConversationBufferMemory(
    chat_memory=chat_history,
    memory_key="history",  # REQUIRED in newer versions
    return_messages=True
)

def retrieve_product(user_input):
    """Retrieve relevant context from Pinecone and return a structured summary."""
    if user_input is None:
        return "Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p."  # Return an appropriate message if input is None

    retrieved_info = retrieve_relevant_infov2(user_input, top_k=10)

    if not retrieved_info:
        return "Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p."

    structured_summary = []
    for doc in retrieved_info:
        content = doc.get("content", "").strip()
        if content:
            structured_summary.append(content)
    return "\n\n".join(structured_summary) if structured_summary else "Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p."

pc = Pinecone(api_key=PINECONE_API_KEY)

# Check if index exists
existing_indexes = [i['name'] for i in pc.list_indexes()]
if index_name not in existing_indexes:
    pc.create_index(
        name=index_name,
        dimension=1536,  # Ensure this matches your model's output dimension
        metric="cosine",
        spec=ServerlessSpec(cloud="aws", region="us-east-1")
    )

def handle_user_message(user_message, user_context):
    """
    X·ª≠ l√Ω tin nh·∫Øn t·ª´ ng∆∞·ªùi d√πng, x√°c ƒë·ªãnh m·ª•c ti√™u, t·∫°o Best_map v√† d·∫´n d·∫Øt h·ªôi tho·∫°i.
    """
    # B∆∞·ªõc 1: Ph√¢n t√≠ch kh√°ch h√†ng t·ª´ context
    customer_info = get_customer_info(user_context)
    print("customer_info:", customer_info)
    
    # B∆∞·ªõc 2: X√°c ƒë·ªãnh m·ª•c ti√™u h·ªôi tho·∫°i
    conversation_goal = determine_conversation_goal(user_message, customer_info)
    print("conversation_goal:", conversation_goal)

    # B∆∞·ªõc 3: T·∫°o Best_map (b·∫£n ƒë·ªì d·∫´n ƒë·∫øn th√†nh c√¥ng)
    #best_map = create_best_map(conversation_goal)
    best_map = create_best_map(conversation_goal, user_context.get("customer_info", {}))


    # B∆∞·ªõc 4: D·∫´n d·∫Øt h·ªôi tho·∫°i theo Best_map
    response = guide_conversation(user_message, best_map, customer_info)
    #response = "test"
    return response

def get_customer_info(user_context):
    """
    Ph√¢n t√≠ch kh√°ch h√†ng t·ª´ context ƒë·ªÉ hi·ªÉu r√µ h∆°n v·ªÅ ng∆∞·ªùi d√πng.
    """
    if user_context is None:
        return {"name": "Kh√°ch h√†ng", "age": None, "gender": None, "profession": None}  

    customer_info = {
        "name": user_context.get("name"),
        "age": user_context.get("age"),
        "gender": user_context.get("gender"),
        "occupation": user_context.get("occupation"),
        "interests": user_context.get("interests"),
        "purchase_history": user_context.get("purchase_history"),
    }

    # N·∫øu thi·∫øu th√¥ng tin quan tr·ªçng, y√™u c·∫ßu b·ªï sung
    missing_info = [key for key, value in customer_info.items() if value is None]

    if missing_info:
        return {"status": "missing_info", "missing_fields": missing_info}

    return {"status": "complete", "customer_info": customer_info}

import regex as re
def update_customer_info(user_message, customer_info):
    """
    Ph√¢n t√≠ch tin nh·∫Øn ng∆∞·ªùi d√πng ƒë·ªÉ c·∫≠p nh·∫≠t th√¥ng tin kh√°ch h√†ng.
    """
    updated = False

    age_match = re.search(r'(\d{1,2}) tu·ªïi', user_message)
    if age_match:
        customer_info["age"] = int(age_match.group(1))
        customer_info["missing_fields"].remove("age")
        updated = True

    name_match = re.search(r'(t√¥i t√™n l√†|anh l√†|em l√†|t√™n t√¥i l√†)\s*([\w\s]+)', user_message, re.IGNORECASE)
    if name_match:
        customer_info["name"] = name_match.group(2).strip()
        customer_info["missing_fields"].remove("name")
        updated = True

    occupation_match = re.search(r'anh l√†m (\w+)', user_message, re.IGNORECASE)
    if occupation_match:
        customer_info["occupation"] = occupation_match.group(1)
        customer_info["missing_fields"].remove("occupation")
        updated = True

    if updated:
        customer_info["status"] = "info_updated"

    return customer_info


def determine_conversation_goal(customer_info, user_message):
    """
    X√°c ƒë·ªãnh m·ª•c ti√™u h·ªôi tho·∫°i d·ª±a tr√™n th√¥ng tin kh√°ch h√†ng v√† tin nh·∫Øn.
    """
    if "missing_fields" in customer_info and len(customer_info["missing_fields"]) > 0:
        return "Kh·ªüi t·∫°o h·ªôi tho·∫°i chung"
    
    if "mu·ªën cao th√™m" in user_message:
        return "T∆∞ v·∫•n s·∫£n ph·∫©m tƒÉng chi·ªÅu cao"
    
    return "Ti·∫øp t·ª•c h·ªôi tho·∫°i"


def determine_conversation_goal_v1(user_message, customer_info):
    """
    X√°c ƒë·ªãnh m·ª•c ti√™u c·ªßa cu·ªôc tr√≤ chuy·ªán d·ª±a tr√™n tin nh·∫Øn c·ªßa user v√† th√¥ng tin kh√°ch h√†ng.
    """
    if not customer_info or customer_info.get("name") is None:
        return "Kh·ªüi t·∫°o h·ªôi tho·∫°i chung"
    
    if customer_info.get("status") == "missing_info":
        missing_fields = customer_info.get("missing_fields", [])
        if missing_fields:
            return f"H√£y h·ªèi th√™m v·ªÅ {', '.join(missing_fields)} tr∆∞·ªõc khi ti·∫øp t·ª•c."
        return "Kh·ªüi t·∫°o h·ªôi tho·∫°i chung"
    
    # D·ª±a tr√™n tin nh·∫Øn c·ªßa user ƒë·ªÉ x√°c ƒë·ªãnh intent
    if "tƒÉng chi·ªÅu cao" in user_message:
        return "T∆∞ v·∫•n s·∫£n ph·∫©m tƒÉng chi·ªÅu cao"
    if "gi·∫£m c√¢n" in user_message:
        return "T∆∞ v·∫•n s·∫£n ph·∫©m gi·∫£m c√¢n"
    if "mu·ªën t√¨m hi·ªÉu" in user_message:
        return "Cung c·∫•p th√¥ng tin chi ti·∫øt v·ªÅ s·∫£n ph·∫©m"
    if "gi√° bao nhi√™u" in user_message:
        return "Cung c·∫•p th√¥ng tin gi√° s·∫£n ph·∫©m"
    if "t∆∞ v·∫•n gi√∫p" in user_message:
        return "T∆∞ v·∫•n c√° nh√¢n h√≥a d·ª±a tr√™n nhu c·∫ßu kh√°ch h√†ng"
    
    return "D·∫´n d·∫Øt h·ªôi tho·∫°i ƒë·ªÉ t√¨m hi·ªÉu nhu c·∫ßu kh√°ch h√†ng"

def create_best_map(conversation_goal, customer_info):
    print("customer_info in the conversation_goal:", customer_info)
    """
    T·∫°o b·∫£n ƒë·ªì h·ªôi tho·∫°i t·ªët nh·∫•t d·ª±a tr√™n m·ª•c ti√™u h·ªôi tho·∫°i v√† th√¥ng tin kh√°ch h√†ng.
    """
    if conversation_goal == "Kh·ªüi t·∫°o h·ªôi tho·∫°i chung":
        missing = customer_info.get("missing_fields", [])
        if "name" in missing:
            return ["B∆∞·ªõc 1: H·ªèi t√™n kh√°ch h√†ng"]
        if "age" in missing:
            return ["B∆∞·ªõc 2: H·ªèi tu·ªïi kh√°ch h√†ng"]
        if "occupation" in missing:
            return ["B∆∞·ªõc 3: H·ªèi ngh·ªÅ nghi·ªáp kh√°ch h√†ng"]
        return ["B∆∞·ªõc 4: Ho√†n th√†nh h·ªì s∆° kh√°ch h√†ng"]

    if conversation_goal == "T∆∞ v·∫•n s·∫£n ph·∫©m tƒÉng chi·ªÅu cao":
        return [
            "B∆∞·ªõc 1: X√°c nh·∫≠n mong mu·ªën tƒÉng chi·ªÅu cao",
            "B∆∞·ªõc 2: Gi·ªõi thi·ªáu s·∫£n ph·∫©m ph√π h·ª£p",
            "B∆∞·ªõc 3: Gi·∫£i ƒë√°p th·∫Øc m·∫Øc"
        ]
    
    return ["B∆∞·ªõc 1: Ti·∫øp t·ª•c h·ªôi tho·∫°i"]


def create_best_map_v1(conversation_goal):
    """
    D·ª±a v√†o m·ª•c ti√™u h·ªôi tho·∫°i, t√¨m c√°c k·ªπ nƒÉng ph√π h·ª£p trong Pinecone ƒë·ªÉ x√¢y d·ª±ng Best_map.
    """
    relevant_skills = search_sales_skills(conversation_goal)
    print("DEBUG: relevant_skills =", relevant_skills)
    
    best_map = []
    
    if conversation_goal == "Kh·ªüi t·∫°o h·ªôi tho·∫°i chung":
        best_map.append("B∆∞·ªõc 1: Ch√†o h·ªèi v√† t√¨m hi·ªÉu nhu c·∫ßu kh√°ch h√†ng")
    
    if "khai th√°c th√¥ng tin c√° nh√¢n" in relevant_skills:
        best_map.append("B∆∞·ªõc 1: Khai th√°c th√¥ng tin kh√°ch h√†ng (T√™n, tu·ªïi, ngh·ªÅ nghi·ªáp)")
    if "kh∆°i g·ª£i ƒë·ªông l·ª±c" in relevant_skills:
        best_map.append("B∆∞·ªõc 2: Kh∆°i g·ª£i ƒë·ªông l·ª±c (L·ª£i √≠ch s·∫£n ph·∫©m, t√°c ƒë·ªông th·ª±c t·∫ø)")
    if "ƒë∆∞a v√≠ d·ª• thuy·∫øt ph·ª•c" in relevant_skills:
        best_map.append("B∆∞·ªõc 3: ƒê∆∞a v√≠ d·ª• th·ª±c t·∫ø (C√¢u chuy·ªán th√†nh c√¥ng c·ªßa kh√°ch h√†ng kh√°c)")
    if "ƒë·ªÅ xu·∫•t gi·∫£i ph√°p" in relevant_skills:
        best_map.append("B∆∞·ªõc 4: ƒê·ªÅ xu·∫•t s·∫£n ph·∫©m ph√π h·ª£p v·ªõi nhu c·∫ßu kh√°ch h√†ng")
    
    # N·∫øu kh√¥ng c√≥ b∆∞·ªõc n√†o, cung c·∫•p fallback
    if not best_map:
        best_map.append("B∆∞·ªõc 1: M·ªü ƒë·∫ßu cu·ªôc tr√≤ chuy·ªán")
    
    print("DEBUG: best_map =", best_map)
    return best_map

def guide_conversation(user_message, best_map, customer_info):
    """
    H∆∞·ªõng d·∫´n h·ªôi tho·∫°i d·ª±a tr√™n tin nh·∫Øn ng∆∞·ªùi d√πng, Best_map v√† th√¥ng tin kh√°ch h√†ng.
    """
    print(f"DEBUG: user_message = {user_message}")
    print(f"DEBUG: best_map = {best_map}")
    
    # ƒê·∫£m b·∫£o best_map c√≥ √≠t nh·∫•t 3 ph·∫ßn t·ª≠ tr∆∞·ªõc khi truy c·∫≠p
    step_1 = best_map[0] if len(best_map) > 0 else "B∆∞·ªõc 1: Ch√†o h·ªèi v√† t√¨m hi·ªÉu nhu c·∫ßu kh√°ch h√†ng"
    step_2 = best_map[1] if len(best_map) > 1 else None
    step_3 = best_map[2] if len(best_map) > 2 else None

    # B∆∞·ªõc 1: Ch√†o h·ªèi n·∫øu ch∆∞a c√≥ th√¥ng tin kh√°ch h√†ng
    if step_1 and "ch√†o" in user_message.lower():
        return "Xin ch√†o! B·∫°n c√≥ th·ªÉ cho m√¨nh bi·∫øt th√™m v·ªÅ b·∫°n kh√¥ng? (T√™n, tu·ªïi, ngh·ªÅ nghi·ªáp...)"

    # B∆∞·ªõc 2: Khai th√°c th√¥ng tin c√° nh√¢n
    if step_2 and "t√™n t√¥i" in user_message.lower():
        return f"C·∫£m ∆°n {user_message.split('t√™n t√¥i l√†')[-1].strip()}! B·∫°n c√≥ th·ªÉ chia s·∫ª th√™m s·ªü th√≠ch ho·∫∑c nhu c·∫ßu c·ªßa m√¨nh kh√¥ng?"

    # B∆∞·ªõc 3: X·ª≠ l√Ω nghi ng·ªù ho·∫∑c ph·∫£n ƒë·ªëi
    if step_3 and "nghi ng·ªù" in user_message.lower():
        return "T√¥i hi·ªÉu b·∫°n c√≥ m·ªôt s·ªë th·∫Øc m·∫Øc. ƒê√¢y l√† m·ªôt s·ªë ph·∫£n h·ªìi t·ª´ kh√°ch h√†ng ƒë√£ t·ª´ng s·ª≠ d·ª•ng s·∫£n ph·∫©m c·ªßa ch√∫ng t√¥i..."

    # N·∫øu kh√¥ng kh·ªõp b·∫•t k·ª≥ b∆∞·ªõc n√†o, d·∫´n d·∫Øt l·∫°i
    return "B·∫°n c√≥ th·ªÉ n√≥i r√µ h∆°n v·ªÅ nhu c·∫ßu ho·∫∑c c√¢u h·ªèi c·ªßa b·∫°n kh√¥ng?"


def search_sales_skills(query_text, max_skills=3):
    """ 
    Truy v·∫•n k·ªπ nƒÉng t·ª´ Pinecone v·ªõi ƒë·ªô ch√≠nh x√°c cao h∆°n. 
    """
    embedding_model = OpenAIEmbeddings(model="text-embedding-3-large", dimensions=1536)
    query_embedding = embedding_model.embed_query(query_text)

    index = pc.Index(index_name)
    response = index.query(
        vector=query_embedding,
        top_k=max_skills,
        include_metadata=True  
    )

    skills = []
    if response and "matches" in response:
        for match in response["matches"]:
            skill_text = match.get("metadata", {}).get("content")
            if skill_text:
                skills.append(skill_text)

    return skills if skills else ["Kh√¥ng t√¨m th·∫•y k·ªπ nƒÉng ph√π h·ª£p."]


def search_sales_skills_basic(query_text, max_skills=3):
    """Truy v·∫•n k·ªπ nƒÉng b√°n h√†ng t·ª´ Pinecone d·ª±a tr√™n ƒë·ªô t∆∞∆°ng ƒë·ªìng v·ªõi input c·ªßa ng∆∞·ªùi d√πng."""
    embedding_model = OpenAIEmbeddings(model="text-embedding-3-large", dimensions=1536)
    query_embedding = embedding_model.embed_query(query_text)

    # T√¨m ki·∫øm trong Pinecone
    index = pc.Index(index_name)
    response = index.query(
        vector=query_embedding,
        top_k=max_skills,  
        include_metadata=True  
    )

    skills = []
    if response and "matches" in response:
        for match in response["matches"]:
            skill_text = match.get("metadata", {}).get("content")
            score = match.get("score", 0.0)  # L·∫•y ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng

            # üöÄ Ch·ªâ lo·∫°i b·ªè n·∫øu score < 0.0 (c√≤n l·∫°i v·∫´n l·∫•y)
            if skill_text and score >= 0.0:  
                skills.append(skill_text)

    print("üîç K·ªπ nƒÉng t√¨m ƒë∆∞·ª£c:", skills)
    return skills if skills else ["Kh√¥ng t√¨m th·∫•y k·ªπ nƒÉng ph√π h·ª£p."]


def search_sales_skills_ok1(query_text, max_skills=3):
    """Truy v·∫•n k·ªπ nƒÉng b√°n h√†ng t·ª´ Pinecone d·ª±a tr√™n ƒë·ªô t∆∞∆°ng ƒë·ªìng v·ªõi input c·ªßa ng∆∞·ªùi d√πng."""
    
    # üîπ N·∫øu l√† c√¢u ch√†o, t√¨m k·ªπ nƒÉng m·ªü ƒë·∫ßu
    greeting_keywords = ["ch√†o", "hello", "hi", "xin ch√†o"]
    if any(word in query_text.lower() for word in greeting_keywords):
        query_text = "K·ªπ nƒÉng m·ªü l·ªùi"
    
    embedding_model = OpenAIEmbeddings(model="text-embedding-3-large", dimensions=1536)
    query_embedding = embedding_model.embed_query(query_text)

    try:
        # üî• G·ªçi Pinecone ƒë·ªÉ t√¨m k·ªπ nƒÉng g·∫ßn nh·∫•t
        index = pc.Index(index_name)
        response = index.query(
            vector=query_embedding,
            top_k=max_skills,  
            include_metadata=True  
        )

        skills = []
        if response and "matches" in response:
            for match in response["matches"]:
                score = match.get("score", 0)
                skill_text = match.get("metadata", {}).get("content").strip()
                # üîπ L·ªçc k·∫øt qu·∫£ d·ª±a tr√™n ng∆∞·ª°ng (threshold)
                if skill_text and score >= 0.6:  # Gi·∫£m threshold ƒë·ªÉ kh√¥ng b·ªè s√≥t k·ªπ nƒÉng
                    skills.append(skill_text)

        # üîπ L·ªçc b·ªè k·ªπ nƒÉng tr√πng l·∫∑p
        unique_skills = list(set(skills))

        print("üîç K·ªπ nƒÉng t√¨m ƒë∆∞·ª£c:", unique_skills)
        return unique_skills if unique_skills else ["Kh√¥ng t√¨m th·∫•y k·ªπ nƒÉng ph√π h·ª£p."]

    except Exception as e:
        print("‚ö†Ô∏è L·ªói truy v·∫•n Pinecone:", str(e))
        return ["Kh√¥ng t√¨m th·∫•y k·ªπ nƒÉng ph√π h·ª£p."]


chain = (
    RunnablePassthrough.assign(
        history=lambda _: memory.load_memory_variables({}).get("history", []),
        products=lambda x: retrieve_product(x["user_input"]),
        sales_skills=lambda x: ", ".join(search_sales_skills(x["user_input"], max_skills=3)),  # L·∫•y k·ªπ nƒÉng t·ª´ Pinecone
        user_style=lambda _: "l·ªãch s·ª±"
    )  
    | prompt
    | llm
)

def ami_selling_basic(query):
    print("query:", query)
    input_data = {"user_input": query}
    # L·∫•y k·ªπ nƒÉng ph√π h·ª£p
    relevant_skills = search_sales_skills(query)

    # N·∫øu c√≥ k·ªπ nƒÉng, s·ª≠a query ƒë·ªÉ nh·∫Øc AMI
    if relevant_skills and relevant_skills[0] != "Kh√¥ng t√¨m th·∫•y k·ªπ nƒÉng ph√π h·ª£p.":
        input_data["user_input"] += f"\n\nüìå H√£y √°p d·ª•ng k·ªπ nƒÉng n√†y v√†o c√¢u tr·∫£ l·ªùi: {', '.join(relevant_skills)}"

    last_response =""
    response_stream = chain.stream(input_data)
    yield from (chunk.content if hasattr(chunk, 'content') else chunk for chunk in response_stream)  # Handle both cases
    #yield "Hey hello I'm Ami" # ‚úÖ C√°ch kh√°c
    memory.save_context({"input": query}, {"output": last_response.strip()})
def ami_selling(user_message, user_context=None):
    """
    H√†m ch√≠nh x·ª≠ l√Ω h·ªôi tho·∫°i b√°n h√†ng c·ªßa Ami.
    """
    if user_context is None:
        user_context = {}
    # G·ªçi handle_user_message ƒë·ªÉ l·∫•y ph·∫£n h·ªìi ch√≠nh theo Best_map
    response = handle_user_message(user_message, user_context)

    # B·ªï sung y·∫øu t·ªë b√°n h√†ng v√†o ph·∫£n h·ªìi
    sales_prompt = "ƒê√¢y l√† s·∫£n ph·∫©m em ƒë·ªÅ xu·∫•t cho anh/ch·ªã: ..."
    if "B∆∞·ªõc 4" in response:
        response += f"\n{sales_prompt}"

    return response
